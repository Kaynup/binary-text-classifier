2025-07-21 11:50:44,790 - __main__ - INFO - ==================================================
2025-07-21 11:50:44,791 - __main__ - INFO - BERT Fine-tuning Training Session Started
2025-07-21 11:50:44,791 - __main__ - INFO - Session Time: 2025-07-21 11:50:44
2025-07-21 11:50:44,791 - __main__ - INFO - ==================================================
2025-07-21 11:50:44,791 - __main__ - INFO - Checking system resources...
2025-07-21 11:50:44,792 - __main__ - INFO - CPU Count: 16 physical, 32 logical
2025-07-21 11:50:45,865 - __main__ - INFO - CPU Usage: 0.0%
2025-07-21 11:50:45,866 - __main__ - INFO - Total RAM: 7.61 GB
2025-07-21 11:50:45,866 - __main__ - INFO - Available RAM: 6.50 GB
2025-07-21 11:50:45,866 - __main__ - INFO - RAM Usage: 14.5%
2025-07-21 11:50:47,685 - __main__ - INFO - CUDA Available: True
2025-07-21 11:50:47,723 - __main__ - INFO - CUDA Device Count: 1
2025-07-21 11:50:47,725 - __main__ - INFO - Current CUDA Device: 0
2025-07-21 11:50:47,725 - __main__ - INFO - CUDA Device Name: NVIDIA GeForce RTX 4060 Laptop GPU
2025-07-21 11:50:47,760 - __main__ - INFO - GPU 0: NVIDIA GeForce RTX 4060 Laptop GPU
2025-07-21 11:50:47,760 - __main__ - INFO -   Memory Total: 8188.0 MB
2025-07-21 11:50:47,760 - __main__ - INFO -   Memory Used: 0.0 MB
2025-07-21 11:50:47,760 - __main__ - INFO -   Memory Free: 7957.0 MB
2025-07-21 11:50:47,760 - __main__ - INFO -   GPU Load: 0.0%
2025-07-21 11:50:47,760 - __main__ - INFO - Model load path: Distilbert_base-model
2025-07-21 11:50:47,760 - __main__ - INFO - Starting model loading process from: Distilbert_base-model
2025-07-21 11:50:47,760 - __main__ - INFO - Loading BERT tokenizer...
2025-07-21 11:50:47,779 - __main__ - INFO -   Tokenizer loaded successfully in 0.02 seconds
2025-07-21 11:50:47,779 - __main__ - INFO -   Vocabulary size: 30522
2025-07-21 11:50:47,779 - __main__ - INFO -   Model max length: 512
2025-07-21 11:50:47,779 - __main__ - INFO -   Special tokens: {'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'}
2025-07-21 11:50:47,779 - __main__ - INFO - Loading BERT model for sequence classification...
2025-07-21 11:50:47,799 - __main__ - INFO - ✓ Model loaded successfully in 0.02 seconds
2025-07-21 11:50:47,799 - __main__ - INFO -   Model type: DistilBertForSequenceClassification
2025-07-21 11:50:47,800 - __main__ - INFO -   Number of parameters: 66,955,010
2025-07-21 11:50:47,800 - __main__ - INFO -   Number of labels: 2
2025-07-21 11:50:47,800 - __main__ - INFO -   Model configuration: DistilBertConfig {
  "activation": "gelu",
  "architectures": [
    "DistilBertForSequenceClassification"
  ],
  "attention_dropout": 0.1,
  "dim": 768,
  "dropout": 0.1,
  "hidden_dim": 3072,
  "initializer_range": 0.02,
  "max_position_embeddings": 512,
  "model_type": "distilbert",
  "n_heads": 12,
  "n_layers": 6,
  "pad_token_id": 0,
  "qa_dropout": 0.1,
  "seq_classif_dropout": 0.2,
  "sinusoidal_pos_embds": false,
  "tie_weights_": true,
  "torch_dtype": "float32",
  "transformers_version": "4.53.2",
  "vocab_size": 30522
}

2025-07-21 11:50:47,800 - __main__ - INFO -   Model device: cpu
2025-07-21 11:50:47,800 - __main__ - INFO - Total loading time: 0.04 seconds
2025-07-21 11:50:47,800 - __main__ - INFO - Loading training and validation datasets...
2025-07-21 11:50:47,800 - __main__ - INFO - Loading dataset from: train_dataset.pt
2025-07-21 11:51:05,439 - __main__ - INFO - ✓ Dataset loaded in 17.64 seconds
2025-07-21 11:51:05,439 - __main__ - INFO -   Dataset size: 766706
2025-07-21 11:51:05,440 - __main__ - INFO - Loading dataset from: val_dataset.pt
2025-07-21 11:51:07,043 - __main__ - INFO - ✓ Dataset loaded in 1.60 seconds
2025-07-21 11:51:07,044 - __main__ - INFO -   Dataset size: 85190
2025-07-21 11:51:07,044 - __main__ - INFO - Training dataset size: 766706
2025-07-21 11:51:07,044 - __main__ - INFO - Validation dataset size: 85190
2025-07-21 11:51:07,044 - __main__ - INFO - Configuring training arguments...
2025-07-21 11:51:08,758 - __main__ - INFO - Training Configuration:
2025-07-21 11:51:08,758 - __main__ - INFO -   Output directory: .Bert-finetuned/results
2025-07-21 11:51:08,758 - __main__ - INFO -   Evaluation strategy: epoch
2025-07-21 11:51:08,758 - __main__ - INFO -   Training batch size: 64
2025-07-21 11:51:08,758 - __main__ - INFO -   Evaluation batch size: 64
2025-07-21 11:51:08,758 - __main__ - INFO -   Number of epochs: 3
2025-07-21 11:51:08,758 - __main__ - INFO -   Weight decay: 0.01
2025-07-21 11:51:08,758 - __main__ - INFO -   FP16 enabled: True
2025-07-21 11:51:08,758 - __main__ - INFO -   Logging steps: 50
2025-07-21 11:51:08,758 - __main__ - INFO -   Save total limit: 5
2025-07-21 11:51:08,758 - __main__ - INFO -   DataLoader workers: 4
2025-07-21 11:51:08,758 - __main__ - INFO - Initializing Trainer...
2025-07-21 11:51:09,043 - __main__ - INFO - Trainer initialized successfully
2025-07-21 11:51:09,043 - __main__ - INFO - FP16 Training Enabled: True
2025-07-21 11:51:09,043 - __main__ - INFO - ==================================================
2025-07-21 11:51:09,043 - __main__ - INFO - STARTING TRAINING PROCESS
2025-07-21 11:51:09,043 - __main__ - INFO - ==================================================
2025-07-21 11:51:10,648 - __main__ - INFO - Training started!
2025-07-21 11:51:10,649 - __main__ - INFO - Total epochs planned: 3
2025-07-21 11:51:10,649 - __main__ - INFO - Training batch size: 64
2025-07-21 11:51:10,649 - __main__ - INFO - Evaluation batch size: 64
2025-07-21 11:51:10,650 - __main__ - INFO - Starting Epoch 1/3
2025-07-21 11:51:17,577 - __main__ - INFO - Step 50: {'loss': 0.5259, 'grad_norm': 3.1093931198120117, 'learning_rate': 4.9931830829159716e-05, 'epoch': 0.004173622704507512}
2025-07-21 11:51:25,714 - __main__ - INFO - Step 100: {'loss': 0.4261, 'grad_norm': 2.220524311065674, 'learning_rate': 4.9862270450751256e-05, 'epoch': 0.008347245409015025}
2025-07-21 11:51:34,010 - __main__ - INFO - Step 150: {'loss': 0.4232, 'grad_norm': 3.882155418395996, 'learning_rate': 4.9792710072342796e-05, 'epoch': 0.012520868113522538}
2025-07-21 11:51:42,301 - __main__ - INFO - Step 200: {'loss': 0.4118, 'grad_norm': 3.089057207107544, 'learning_rate': 4.972314969393434e-05, 'epoch': 0.01669449081803005}
2025-07-21 11:51:48,199 - __main__ - INFO - Step 250: {'loss': 0.393, 'grad_norm': 2.9753243923187256, 'learning_rate': 4.9653589315525877e-05, 'epoch': 0.020868113522537562}
2025-07-21 11:51:56,441 - __main__ - INFO - Step 300: {'loss': 0.3844, 'grad_norm': 2.548039674758911, 'learning_rate': 4.9584028937117424e-05, 'epoch': 0.025041736227045076}
2025-07-21 11:52:04,788 - __main__ - INFO - Step 350: {'loss': 0.3701, 'grad_norm': 1.87288498878479, 'learning_rate': 4.951446855870896e-05, 'epoch': 0.02921535893155259}
2025-07-21 11:52:13,248 - __main__ - INFO - Step 400: {'loss': 0.3781, 'grad_norm': 3.3169338703155518, 'learning_rate': 4.9444908180300504e-05, 'epoch': 0.0333889816360601}
2025-07-21 11:52:19,101 - __main__ - INFO - Step 450: {'loss': 0.3711, 'grad_norm': 2.4174134731292725, 'learning_rate': 4.9375347801892044e-05, 'epoch': 0.037562604340567615}
2025-07-21 11:52:27,307 - __main__ - INFO - Step 500: {'loss': 0.3669, 'grad_norm': 3.904834270477295, 'learning_rate': 4.9305787423483584e-05, 'epoch': 0.041736227045075125}
2025-07-21 11:52:35,624 - __main__ - INFO - Step 550: {'loss': 0.3815, 'grad_norm': 2.2410244941711426, 'learning_rate': 4.923622704507513e-05, 'epoch': 0.045909849749582635}
2025-07-21 11:52:44,008 - __main__ - INFO - Step 600: {'loss': 0.3453, 'grad_norm': 2.793952226638794, 'learning_rate': 4.9166666666666665e-05, 'epoch': 0.05008347245409015}
2025-07-21 11:52:49,855 - __main__ - INFO - Step 650: {'loss': 0.3506, 'grad_norm': 2.596144914627075, 'learning_rate': 4.909710628825821e-05, 'epoch': 0.05425709515859766}
2025-07-21 11:52:58,030 - __main__ - INFO - Step 700: {'loss': 0.3641, 'grad_norm': 2.492562770843506, 'learning_rate': 4.902754590984975e-05, 'epoch': 0.05843071786310518}
2025-07-21 11:53:06,383 - __main__ - INFO - Step 750: {'loss': 0.3585, 'grad_norm': 2.952716588973999, 'learning_rate': 4.895798553144129e-05, 'epoch': 0.06260434056761269}
2025-07-21 11:53:14,690 - __main__ - INFO - Step 800: {'loss': 0.3415, 'grad_norm': 3.3795504570007324, 'learning_rate': 4.888842515303283e-05, 'epoch': 0.0667779632721202}
2025-07-21 11:53:20,616 - __main__ - INFO - Step 850: {'loss': 0.3455, 'grad_norm': 3.460313558578491, 'learning_rate': 4.881886477462438e-05, 'epoch': 0.0709515859766277}
2025-07-21 11:53:28,851 - __main__ - INFO - Step 900: {'loss': 0.3245, 'grad_norm': 2.3856935501098633, 'learning_rate': 4.874930439621592e-05, 'epoch': 0.07512520868113523}
2025-07-21 11:53:37,182 - __main__ - INFO - Step 950: {'loss': 0.3517, 'grad_norm': 2.098546266555786, 'learning_rate': 4.867974401780746e-05, 'epoch': 0.07929883138564274}
2025-07-21 11:53:45,508 - __main__ - INFO - Step 1000: {'loss': 0.3381, 'grad_norm': 2.1269640922546387, 'learning_rate': 4.8610183639399e-05, 'epoch': 0.08347245409015025}
2025-07-21 11:53:51,298 - __main__ - INFO - Step 1050: {'loss': 0.338, 'grad_norm': 2.0134694576263428, 'learning_rate': 4.854062326099054e-05, 'epoch': 0.08764607679465776}
2025-07-21 11:53:59,524 - __main__ - INFO - Step 1100: {'loss': 0.3629, 'grad_norm': 2.3519747257232666, 'learning_rate': 4.847106288258209e-05, 'epoch': 0.09181969949916527}
2025-07-21 11:54:07,897 - __main__ - INFO - Step 1150: {'loss': 0.3374, 'grad_norm': 2.244011640548706, 'learning_rate': 4.840150250417363e-05, 'epoch': 0.09599332220367279}
2025-07-21 11:54:16,157 - __main__ - INFO - Step 1200: {'loss': 0.3489, 'grad_norm': 1.4788260459899902, 'learning_rate': 4.833194212576517e-05, 'epoch': 0.1001669449081803}
2025-07-21 11:54:22,025 - __main__ - INFO - Step 1250: {'loss': 0.357, 'grad_norm': 1.9914849996566772, 'learning_rate': 4.826238174735671e-05, 'epoch': 0.10434056761268781}
2025-07-21 11:54:30,280 - __main__ - INFO - Step 1300: {'loss': 0.3378, 'grad_norm': 2.4766461849212646, 'learning_rate': 4.819282136894825e-05, 'epoch': 0.10851419031719532}
2025-07-21 11:54:38,580 - __main__ - INFO - Step 1350: {'loss': 0.3433, 'grad_norm': 2.200129508972168, 'learning_rate': 4.8123260990539794e-05, 'epoch': 0.11268781302170283}
2025-07-21 11:54:46,901 - __main__ - INFO - Step 1400: {'loss': 0.3511, 'grad_norm': 1.956860065460205, 'learning_rate': 4.805370061213133e-05, 'epoch': 0.11686143572621036}
2025-07-21 11:54:52,827 - __main__ - INFO - Step 1450: {'loss': 0.328, 'grad_norm': 2.424647569656372, 'learning_rate': 4.7984140233722875e-05, 'epoch': 0.12103505843071787}
2025-07-21 11:55:01,085 - __main__ - INFO - Step 1500: {'loss': 0.3595, 'grad_norm': 1.556208610534668, 'learning_rate': 4.7914579855314415e-05, 'epoch': 0.12520868113522537}
2025-07-21 11:55:09,431 - __main__ - INFO - Step 1550: {'loss': 0.3309, 'grad_norm': 2.7141149044036865, 'learning_rate': 4.7845019476905955e-05, 'epoch': 0.1293823038397329}
2025-07-21 11:55:17,724 - __main__ - INFO - Step 1600: {'loss': 0.3268, 'grad_norm': 2.0020484924316406, 'learning_rate': 4.77754590984975e-05, 'epoch': 0.1335559265442404}
2025-07-21 11:55:23,662 - __main__ - INFO - Step 1650: {'loss': 0.3363, 'grad_norm': 1.683208703994751, 'learning_rate': 4.7705898720089036e-05, 'epoch': 0.13772954924874792}
2025-07-21 11:55:31,913 - __main__ - INFO - Step 1700: {'loss': 0.3397, 'grad_norm': 2.333750009536743, 'learning_rate': 4.763633834168058e-05, 'epoch': 0.1419031719532554}
2025-07-21 11:55:40,272 - __main__ - INFO - Step 1750: {'loss': 0.3393, 'grad_norm': 2.7262051105499268, 'learning_rate': 4.756677796327212e-05, 'epoch': 0.14607679465776294}
2025-07-21 11:55:48,514 - __main__ - INFO - Step 1800: {'loss': 0.3327, 'grad_norm': 2.748277187347412, 'learning_rate': 4.749721758486366e-05, 'epoch': 0.15025041736227046}
2025-07-21 11:55:54,418 - __main__ - INFO - Step 1850: {'loss': 0.3328, 'grad_norm': 2.182640790939331, 'learning_rate': 4.74276572064552e-05, 'epoch': 0.15442404006677796}
2025-07-21 11:56:02,776 - __main__ - INFO - Step 1900: {'loss': 0.3299, 'grad_norm': 2.8598580360412598, 'learning_rate': 4.735809682804674e-05, 'epoch': 0.15859766277128548}
2025-07-21 11:56:11,143 - __main__ - INFO - Step 1950: {'loss': 0.3449, 'grad_norm': 1.3307907581329346, 'learning_rate': 4.728853644963829e-05, 'epoch': 0.16277128547579298}
2025-07-21 11:56:19,471 - __main__ - INFO - Step 2000: {'loss': 0.3097, 'grad_norm': 3.0021824836730957, 'learning_rate': 4.721897607122983e-05, 'epoch': 0.1669449081803005}
2025-07-21 11:56:25,334 - __main__ - INFO - Step 2050: {'loss': 0.3118, 'grad_norm': 1.6444889307022095, 'learning_rate': 4.714941569282137e-05, 'epoch': 0.17111853088480802}
2025-07-21 11:56:33,652 - __main__ - INFO - Step 2100: {'loss': 0.322, 'grad_norm': 2.8302526473999023, 'learning_rate': 4.707985531441291e-05, 'epoch': 0.17529215358931552}
2025-07-21 11:56:41,966 - __main__ - INFO - Step 2150: {'loss': 0.3429, 'grad_norm': 1.8098037242889404, 'learning_rate': 4.701029493600446e-05, 'epoch': 0.17946577629382304}
2025-07-21 11:56:47,902 - __main__ - INFO - Step 2200: {'loss': 0.3323, 'grad_norm': 2.9384939670562744, 'learning_rate': 4.694073455759599e-05, 'epoch': 0.18363939899833054}
2025-07-21 11:56:56,161 - __main__ - INFO - Step 2250: {'loss': 0.3194, 'grad_norm': 2.231330156326294, 'learning_rate': 4.687117417918754e-05, 'epoch': 0.18781302170283806}
2025-07-21 11:57:04,492 - __main__ - INFO - Step 2300: {'loss': 0.3151, 'grad_norm': 2.541714668273926, 'learning_rate': 4.680161380077908e-05, 'epoch': 0.19198664440734559}
2025-07-21 11:57:12,819 - __main__ - INFO - Step 2350: {'loss': 0.3245, 'grad_norm': 1.6944552659988403, 'learning_rate': 4.673205342237062e-05, 'epoch': 0.19616026711185308}
2025-07-21 11:57:18,801 - __main__ - INFO - Step 2400: {'loss': 0.3381, 'grad_norm': 2.388683557510376, 'learning_rate': 4.6662493043962165e-05, 'epoch': 0.2003338898163606}
2025-07-21 11:57:27,017 - __main__ - INFO - Step 2450: {'loss': 0.3268, 'grad_norm': 2.180370330810547, 'learning_rate': 4.65929326655537e-05, 'epoch': 0.2045075125208681}
2025-07-21 11:57:35,411 - __main__ - INFO - Step 2500: {'loss': 0.3336, 'grad_norm': 2.184504508972168, 'learning_rate': 4.6523372287145246e-05, 'epoch': 0.20868113522537562}
2025-07-21 11:57:43,650 - __main__ - INFO - Step 2550: {'loss': 0.3113, 'grad_norm': 2.218796968460083, 'learning_rate': 4.6453811908736786e-05, 'epoch': 0.21285475792988315}
2025-07-21 11:57:49,543 - __main__ - INFO - Step 2600: {'loss': 0.3473, 'grad_norm': 1.9865198135375977, 'learning_rate': 4.6384251530328326e-05, 'epoch': 0.21702838063439064}
2025-07-21 11:57:57,853 - __main__ - INFO - Step 2650: {'loss': 0.3122, 'grad_norm': 1.7197074890136719, 'learning_rate': 4.631469115191987e-05, 'epoch': 0.22120200333889817}
2025-07-21 11:58:06,195 - __main__ - INFO - Step 2700: {'loss': 0.3268, 'grad_norm': 1.9768235683441162, 'learning_rate': 4.6245130773511406e-05, 'epoch': 0.22537562604340566}
2025-07-21 11:58:14,479 - __main__ - INFO - Step 2750: {'loss': 0.3141, 'grad_norm': 1.650575041770935, 'learning_rate': 4.6175570395102953e-05, 'epoch': 0.2295492487479132}
2025-07-21 11:58:20,377 - __main__ - INFO - Step 2800: {'loss': 0.3381, 'grad_norm': 1.8861104249954224, 'learning_rate': 4.6106010016694494e-05, 'epoch': 0.2337228714524207}
2025-07-21 11:58:28,617 - __main__ - INFO - Step 2850: {'loss': 0.3204, 'grad_norm': 2.555675745010376, 'learning_rate': 4.6036449638286034e-05, 'epoch': 0.2378964941569282}
2025-07-21 11:58:36,916 - __main__ - INFO - Step 2900: {'loss': 0.3217, 'grad_norm': 2.4572103023529053, 'learning_rate': 4.5966889259877574e-05, 'epoch': 0.24207011686143573}
2025-07-21 11:58:45,212 - __main__ - INFO - Step 2950: {'loss': 0.3145, 'grad_norm': 1.9745689630508423, 'learning_rate': 4.5897328881469114e-05, 'epoch': 0.24624373956594323}
2025-07-21 11:58:51,095 - __main__ - INFO - Step 3000: {'loss': 0.3136, 'grad_norm': 3.2657792568206787, 'learning_rate': 4.582776850306066e-05, 'epoch': 0.25041736227045075}
2025-07-21 11:58:59,377 - __main__ - INFO - Step 3050: {'loss': 0.311, 'grad_norm': 2.0263895988464355, 'learning_rate': 4.57582081246522e-05, 'epoch': 0.25459098497495825}
2025-07-21 11:59:07,774 - __main__ - INFO - Step 3100: {'loss': 0.3238, 'grad_norm': 2.229396104812622, 'learning_rate': 4.568864774624374e-05, 'epoch': 0.2587646076794658}
2025-07-21 11:59:16,014 - __main__ - INFO - Step 3150: {'loss': 0.3152, 'grad_norm': 1.9044890403747559, 'learning_rate': 4.5620478575403455e-05, 'epoch': 0.2629382303839733}
2025-07-21 11:59:21,868 - __main__ - INFO - Step 3200: {'loss': 0.3376, 'grad_norm': 2.0223426818847656, 'learning_rate': 4.5550918196994995e-05, 'epoch': 0.2671118530884808}
2025-07-21 11:59:30,114 - __main__ - INFO - Step 3250: {'loss': 0.316, 'grad_norm': 2.168457269668579, 'learning_rate': 4.5481357818586535e-05, 'epoch': 0.27128547579298834}
2025-07-21 11:59:38,442 - __main__ - INFO - Step 3300: {'loss': 0.3162, 'grad_norm': 2.2428197860717773, 'learning_rate': 4.5411797440178075e-05, 'epoch': 0.27545909849749584}
2025-07-21 11:59:46,706 - __main__ - INFO - Step 3350: {'loss': 0.3122, 'grad_norm': 2.2404654026031494, 'learning_rate': 4.5342237061769616e-05, 'epoch': 0.27963272120200333}
2025-07-21 11:59:52,616 - __main__ - INFO - Step 3400: {'loss': 0.3232, 'grad_norm': 1.8044897317886353, 'learning_rate': 4.527267668336116e-05, 'epoch': 0.2838063439065108}
2025-07-21 12:00:00,879 - __main__ - INFO - Step 3450: {'loss': 0.3051, 'grad_norm': 1.5716056823730469, 'learning_rate': 4.52031163049527e-05, 'epoch': 0.2879799666110184}
2025-07-21 12:00:09,184 - __main__ - INFO - Step 3500: {'loss': 0.3238, 'grad_norm': 1.4903429746627808, 'learning_rate': 4.513355592654424e-05, 'epoch': 0.2921535893155259}
2025-07-21 12:00:19,313 - __main__ - INFO - Step 3550: {'loss': 0.311, 'grad_norm': 1.4471001625061035, 'learning_rate': 4.506399554813578e-05, 'epoch': 0.29632721202003337}
2025-07-21 12:00:28,028 - __main__ - INFO - Step 3600: {'loss': 0.3221, 'grad_norm': 1.1823968887329102, 'learning_rate': 4.499443516972733e-05, 'epoch': 0.3005008347245409}
2025-07-21 12:00:39,271 - __main__ - INFO - Step 3650: {'loss': 0.3043, 'grad_norm': 2.376734972000122, 'learning_rate': 4.4924874791318864e-05, 'epoch': 0.3046744574290484}
2025-07-21 12:00:47,932 - __main__ - INFO - Step 3700: {'loss': 0.3235, 'grad_norm': 2.4070773124694824, 'learning_rate': 4.485531441291041e-05, 'epoch': 0.3088480801335559}
2025-07-21 12:00:58,859 - __main__ - INFO - Step 3750: {'loss': 0.3229, 'grad_norm': 1.8854237794876099, 'learning_rate': 4.478575403450195e-05, 'epoch': 0.31302170283806346}
2025-07-21 12:01:09,873 - __main__ - INFO - Step 3800: {'loss': 0.332, 'grad_norm': 2.048149585723877, 'learning_rate': 4.471619365609349e-05, 'epoch': 0.31719532554257096}
2025-07-21 12:01:18,516 - __main__ - INFO - Step 3850: {'loss': 0.3191, 'grad_norm': 1.4985278844833374, 'learning_rate': 4.464663327768504e-05, 'epoch': 0.32136894824707846}
2025-07-21 12:01:29,431 - __main__ - INFO - Step 3900: {'loss': 0.306, 'grad_norm': 2.441997766494751, 'learning_rate': 4.457707289927657e-05, 'epoch': 0.32554257095158595}
2025-07-21 12:01:40,523 - __main__ - INFO - Step 3950: {'loss': 0.3215, 'grad_norm': 2.359646797180176, 'learning_rate': 4.450751252086812e-05, 'epoch': 0.3297161936560935}
2025-07-21 12:01:49,031 - __main__ - INFO - Step 4000: {'loss': 0.2953, 'grad_norm': 2.791104555130005, 'learning_rate': 4.443795214245965e-05, 'epoch': 0.333889816360601}
2025-07-21 12:01:59,943 - __main__ - INFO - Step 4050: {'loss': 0.3232, 'grad_norm': 1.383003830909729, 'learning_rate': 4.43683917640512e-05, 'epoch': 0.3380634390651085}
2025-07-21 12:02:10,992 - __main__ - INFO - Step 4100: {'loss': 0.317, 'grad_norm': 2.2779929637908936, 'learning_rate': 4.429883138564274e-05, 'epoch': 0.34223706176961605}
2025-07-21 12:02:19,603 - __main__ - INFO - Step 4150: {'loss': 0.3207, 'grad_norm': 2.7277238368988037, 'learning_rate': 4.422927100723428e-05, 'epoch': 0.34641068447412354}
2025-07-21 12:02:30,636 - __main__ - INFO - Step 4200: {'loss': 0.3342, 'grad_norm': 1.587862253189087, 'learning_rate': 4.4159710628825826e-05, 'epoch': 0.35058430717863104}
2025-07-21 12:02:41,726 - __main__ - INFO - Step 4250: {'loss': 0.317, 'grad_norm': 1.8051799535751343, 'learning_rate': 4.4090150250417366e-05, 'epoch': 0.3547579298831386}
2025-07-21 12:02:50,210 - __main__ - INFO - Step 4300: {'loss': 0.3126, 'grad_norm': 1.9374430179595947, 'learning_rate': 4.4020589872008906e-05, 'epoch': 0.3589315525876461}
2025-07-21 12:03:01,070 - __main__ - INFO - Step 4350: {'loss': 0.3052, 'grad_norm': 1.9561707973480225, 'learning_rate': 4.3951029493600446e-05, 'epoch': 0.3631051752921536}
2025-07-21 12:03:12,057 - __main__ - INFO - Step 4400: {'loss': 0.3055, 'grad_norm': 2.3688278198242188, 'learning_rate': 4.3881469115191987e-05, 'epoch': 0.3672787979966611}
2025-07-21 12:03:20,675 - __main__ - INFO - Step 4450: {'loss': 0.3213, 'grad_norm': 1.4376933574676514, 'learning_rate': 4.381190873678353e-05, 'epoch': 0.37145242070116863}
2025-07-21 12:03:31,461 - __main__ - INFO - Step 4500: {'loss': 0.3027, 'grad_norm': 1.699904441833496, 'learning_rate': 4.3742348358375074e-05, 'epoch': 0.3756260434056761}
2025-07-21 12:03:42,367 - __main__ - INFO - Step 4550: {'loss': 0.3053, 'grad_norm': 1.7418630123138428, 'learning_rate': 4.3672787979966614e-05, 'epoch': 0.3797996661101836}
2025-07-21 12:03:50,876 - __main__ - INFO - Step 4600: {'loss': 0.3254, 'grad_norm': 1.3425767421722412, 'learning_rate': 4.3603227601558154e-05, 'epoch': 0.38397328881469117}
2025-07-21 12:04:01,765 - __main__ - INFO - Step 4650: {'loss': 0.3088, 'grad_norm': 2.1340723037719727, 'learning_rate': 4.3533667223149694e-05, 'epoch': 0.38814691151919867}
2025-07-21 12:04:12,759 - __main__ - INFO - Step 4700: {'loss': 0.2979, 'grad_norm': 2.6015238761901855, 'learning_rate': 4.3464106844741234e-05, 'epoch': 0.39232053422370616}
2025-07-21 12:04:21,314 - __main__ - INFO - Step 4750: {'loss': 0.3044, 'grad_norm': 1.590397596359253, 'learning_rate': 4.339454646633278e-05, 'epoch': 0.3964941569282137}
2025-07-21 12:04:32,466 - __main__ - INFO - Step 4800: {'loss': 0.3168, 'grad_norm': 2.7153878211975098, 'learning_rate': 4.332498608792432e-05, 'epoch': 0.4006677796327212}
2025-07-21 12:04:43,512 - __main__ - INFO - Step 4850: {'loss': 0.3107, 'grad_norm': 2.2874550819396973, 'learning_rate': 4.325542570951586e-05, 'epoch': 0.4048414023372287}
2025-07-21 12:04:52,299 - __main__ - INFO - Step 4900: {'loss': 0.2903, 'grad_norm': 1.754286289215088, 'learning_rate': 4.318586533110741e-05, 'epoch': 0.4090150250417362}
2025-07-21 12:05:03,362 - __main__ - INFO - Step 4950: {'loss': 0.3183, 'grad_norm': 2.1573963165283203, 'learning_rate': 4.311630495269894e-05, 'epoch': 0.41318864774624375}
2025-07-21 12:05:14,611 - __main__ - INFO - Step 5000: {'loss': 0.3059, 'grad_norm': 2.3247954845428467, 'learning_rate': 4.304674457429049e-05, 'epoch': 0.41736227045075125}
2025-07-21 12:05:23,127 - __main__ - INFO - Step 5050: {'loss': 0.2997, 'grad_norm': 2.4148316383361816, 'learning_rate': 4.297718419588202e-05, 'epoch': 0.42153589315525875}
2025-07-21 12:05:34,092 - __main__ - INFO - Step 5100: {'loss': 0.297, 'grad_norm': 1.572017788887024, 'learning_rate': 4.290762381747357e-05, 'epoch': 0.4257095158597663}
2025-07-21 12:05:45,157 - __main__ - INFO - Step 5150: {'loss': 0.3034, 'grad_norm': 2.18788480758667, 'learning_rate': 4.283806343906511e-05, 'epoch': 0.4298831385642738}
2025-07-21 12:05:53,675 - __main__ - INFO - Step 5200: {'loss': 0.3087, 'grad_norm': 1.8468643426895142, 'learning_rate': 4.276850306065665e-05, 'epoch': 0.4340567612687813}
2025-07-21 12:06:04,724 - __main__ - INFO - Step 5250: {'loss': 0.3094, 'grad_norm': 1.9382076263427734, 'learning_rate': 4.26989426822482e-05, 'epoch': 0.43823038397328884}
2025-07-21 12:06:15,774 - __main__ - INFO - Step 5300: {'loss': 0.3151, 'grad_norm': 2.101221799850464, 'learning_rate': 4.262938230383973e-05, 'epoch': 0.44240400667779634}
2025-07-21 12:06:24,626 - __main__ - INFO - Step 5350: {'loss': 0.3098, 'grad_norm': 2.514662742614746, 'learning_rate': 4.255982192543128e-05, 'epoch': 0.44657762938230383}
2025-07-21 12:06:35,651 - __main__ - INFO - Step 5400: {'loss': 0.3112, 'grad_norm': 1.8597359657287598, 'learning_rate': 4.249026154702282e-05, 'epoch': 0.4507512520868113}
2025-07-21 12:06:46,868 - __main__ - INFO - Step 5450: {'loss': 0.3038, 'grad_norm': 3.0780370235443115, 'learning_rate': 4.2422092376182524e-05, 'epoch': 0.4549248747913189}
2025-07-21 12:06:55,420 - __main__ - INFO - Step 5500: {'loss': 0.2973, 'grad_norm': 1.730437159538269, 'learning_rate': 4.235253199777407e-05, 'epoch': 0.4590984974958264}
2025-07-21 12:07:06,463 - __main__ - INFO - Step 5550: {'loss': 0.3072, 'grad_norm': 2.069915294647217, 'learning_rate': 4.228297161936561e-05, 'epoch': 0.46327212020033387}
2025-07-21 12:07:17,647 - __main__ - INFO - Step 5600: {'loss': 0.2946, 'grad_norm': 1.9357991218566895, 'learning_rate': 4.221341124095715e-05, 'epoch': 0.4674457429048414}
2025-07-21 12:07:26,220 - __main__ - INFO - Step 5650: {'loss': 0.3294, 'grad_norm': 1.8007482290267944, 'learning_rate': 4.21438508625487e-05, 'epoch': 0.4716193656093489}
2025-07-21 12:07:37,268 - __main__ - INFO - Step 5700: {'loss': 0.3128, 'grad_norm': 2.5069234371185303, 'learning_rate': 4.207429048414023e-05, 'epoch': 0.4757929883138564}
2025-07-21 12:07:48,490 - __main__ - INFO - Step 5750: {'loss': 0.3142, 'grad_norm': 2.1692962646484375, 'learning_rate': 4.200473010573178e-05, 'epoch': 0.47996661101836396}
2025-07-21 12:07:57,284 - __main__ - INFO - Step 5800: {'loss': 0.3036, 'grad_norm': 1.8365612030029297, 'learning_rate': 4.193516972732332e-05, 'epoch': 0.48414023372287146}
2025-07-21 12:08:08,404 - __main__ - INFO - Step 5850: {'loss': 0.3067, 'grad_norm': 2.070858955383301, 'learning_rate': 4.186560934891486e-05, 'epoch': 0.48831385642737896}
2025-07-21 12:08:19,600 - __main__ - INFO - Step 5900: {'loss': 0.3002, 'grad_norm': 1.829451084136963, 'learning_rate': 4.17960489705064e-05, 'epoch': 0.49248747913188645}
2025-07-21 12:08:28,352 - __main__ - INFO - Step 5950: {'loss': 0.3022, 'grad_norm': 2.107635021209717, 'learning_rate': 4.1726488592097946e-05, 'epoch': 0.496661101836394}
2025-07-21 12:08:39,443 - __main__ - INFO - Step 6000: {'loss': 0.2923, 'grad_norm': 1.640990138053894, 'learning_rate': 4.1656928213689486e-05, 'epoch': 0.5008347245409015}
2025-07-21 12:08:48,110 - __main__ - INFO - Step 6050: {'loss': 0.3071, 'grad_norm': 2.121161937713623, 'learning_rate': 4.1587367835281027e-05, 'epoch': 0.505008347245409}
2025-07-21 12:08:58,961 - __main__ - INFO - Step 6100: {'loss': 0.3117, 'grad_norm': 2.103318214416504, 'learning_rate': 4.151780745687257e-05, 'epoch': 0.5091819699499165}
2025-07-21 12:09:10,019 - __main__ - INFO - Step 6150: {'loss': 0.2993, 'grad_norm': 1.6529440879821777, 'learning_rate': 4.144824707846411e-05, 'epoch': 0.513355592654424}
2025-07-21 12:09:18,509 - __main__ - INFO - Step 6200: {'loss': 0.2915, 'grad_norm': 2.2290589809417725, 'learning_rate': 4.1378686700055654e-05, 'epoch': 0.5175292153589316}
2025-07-21 12:09:29,369 - __main__ - INFO - Step 6250: {'loss': 0.3036, 'grad_norm': 1.8516113758087158, 'learning_rate': 4.130912632164719e-05, 'epoch': 0.5217028380634391}
2025-07-21 12:09:40,397 - __main__ - INFO - Step 6300: {'loss': 0.2909, 'grad_norm': 2.2886950969696045, 'learning_rate': 4.1239565943238734e-05, 'epoch': 0.5258764607679466}
2025-07-21 12:09:48,936 - __main__ - INFO - Step 6350: {'loss': 0.3098, 'grad_norm': 1.5609562397003174, 'learning_rate': 4.1170005564830274e-05, 'epoch': 0.5300500834724541}
2025-07-21 12:10:00,072 - __main__ - INFO - Step 6400: {'loss': 0.3107, 'grad_norm': 2.076240301132202, 'learning_rate': 4.1100445186421815e-05, 'epoch': 0.5342237061769616}
2025-07-21 12:10:11,073 - __main__ - INFO - Step 6450: {'loss': 0.2901, 'grad_norm': 4.397619724273682, 'learning_rate': 4.103088480801336e-05, 'epoch': 0.5383973288814691}
2025-07-21 12:10:19,648 - __main__ - INFO - Step 6500: {'loss': 0.3066, 'grad_norm': 2.0204718112945557, 'learning_rate': 4.0961324429604895e-05, 'epoch': 0.5425709515859767}
2025-07-21 12:10:30,619 - __main__ - INFO - Step 6550: {'loss': 0.3003, 'grad_norm': 1.7666716575622559, 'learning_rate': 4.089176405119644e-05, 'epoch': 0.5467445742904842}
2025-07-21 12:10:41,728 - __main__ - INFO - Step 6600: {'loss': 0.2976, 'grad_norm': 1.9524099826812744, 'learning_rate': 4.082220367278798e-05, 'epoch': 0.5509181969949917}
2025-07-21 12:10:50,333 - __main__ - INFO - Step 6650: {'loss': 0.3002, 'grad_norm': 1.6012041568756104, 'learning_rate': 4.075264329437952e-05, 'epoch': 0.5550918196994992}
2025-07-21 12:11:01,222 - __main__ - INFO - Step 6700: {'loss': 0.3103, 'grad_norm': 1.5723456144332886, 'learning_rate': 4.068308291597106e-05, 'epoch': 0.5592654424040067}
2025-07-21 12:11:12,248 - __main__ - INFO - Step 6750: {'loss': 0.3, 'grad_norm': 1.584205150604248, 'learning_rate': 4.06135225375626e-05, 'epoch': 0.5634390651085142}
2025-07-21 12:11:20,790 - __main__ - INFO - Step 6800: {'loss': 0.3003, 'grad_norm': 1.6289362907409668, 'learning_rate': 4.054396215915415e-05, 'epoch': 0.5676126878130217}
2025-07-21 12:11:32,004 - __main__ - INFO - Step 6850: {'loss': 0.2931, 'grad_norm': 1.2172564268112183, 'learning_rate': 4.047440178074569e-05, 'epoch': 0.5717863105175293}
2025-07-21 12:11:43,126 - __main__ - INFO - Step 6900: {'loss': 0.31, 'grad_norm': 1.5658481121063232, 'learning_rate': 4.040484140233723e-05, 'epoch': 0.5759599332220368}
2025-07-21 12:11:51,624 - __main__ - INFO - Step 6950: {'loss': 0.3051, 'grad_norm': 2.30265736579895, 'learning_rate': 4.033528102392877e-05, 'epoch': 0.5801335559265443}
2025-07-21 12:12:02,556 - __main__ - INFO - Step 7000: {'loss': 0.2851, 'grad_norm': 2.6410634517669678, 'learning_rate': 4.026572064552032e-05, 'epoch': 0.5843071786310517}
2025-07-21 12:12:13,677 - __main__ - INFO - Step 7050: {'loss': 0.3021, 'grad_norm': 1.4491595029830933, 'learning_rate': 4.019616026711186e-05, 'epoch': 0.5884808013355592}
2025-07-21 12:12:22,312 - __main__ - INFO - Step 7100: {'loss': 0.2978, 'grad_norm': 2.3277666568756104, 'learning_rate': 4.01265998887034e-05, 'epoch': 0.5926544240400667}
2025-07-21 12:12:33,407 - __main__ - INFO - Step 7150: {'loss': 0.3105, 'grad_norm': 2.026804208755493, 'learning_rate': 4.005703951029494e-05, 'epoch': 0.5968280467445742}
2025-07-21 12:12:44,528 - __main__ - INFO - Step 7200: {'loss': 0.3011, 'grad_norm': 1.6672126054763794, 'learning_rate': 3.998747913188648e-05, 'epoch': 0.6010016694490818}
2025-07-21 12:12:53,051 - __main__ - INFO - Step 7250: {'loss': 0.3121, 'grad_norm': 2.3354623317718506, 'learning_rate': 3.9917918753478025e-05, 'epoch': 0.6051752921535893}
2025-07-21 12:13:03,989 - __main__ - INFO - Step 7300: {'loss': 0.3097, 'grad_norm': 1.764518141746521, 'learning_rate': 3.984835837506956e-05, 'epoch': 0.6093489148580968}
2025-07-21 12:13:15,128 - __main__ - INFO - Step 7350: {'loss': 0.301, 'grad_norm': 2.4545977115631104, 'learning_rate': 3.9778797996661105e-05, 'epoch': 0.6135225375626043}
2025-07-21 12:13:23,861 - __main__ - INFO - Step 7400: {'loss': 0.2953, 'grad_norm': 1.907433032989502, 'learning_rate': 3.9709237618252645e-05, 'epoch': 0.6176961602671118}
2025-07-21 12:13:34,945 - __main__ - INFO - Step 7450: {'loss': 0.3167, 'grad_norm': 1.8241254091262817, 'learning_rate': 3.9639677239844185e-05, 'epoch': 0.6218697829716193}
2025-07-21 12:13:45,945 - __main__ - INFO - Step 7500: {'loss': 0.2884, 'grad_norm': 2.1507112979888916, 'learning_rate': 3.957011686143573e-05, 'epoch': 0.6260434056761269}
2025-07-21 12:13:54,530 - __main__ - INFO - Step 7550: {'loss': 0.3059, 'grad_norm': 1.5009475946426392, 'learning_rate': 3.9500556483027266e-05, 'epoch': 0.6302170283806344}
2025-07-21 12:14:05,519 - __main__ - INFO - Step 7600: {'loss': 0.2775, 'grad_norm': 1.3901479244232178, 'learning_rate': 3.943099610461881e-05, 'epoch': 0.6343906510851419}
2025-07-21 12:14:16,586 - __main__ - INFO - Step 7650: {'loss': 0.2898, 'grad_norm': 2.0183587074279785, 'learning_rate': 3.936143572621035e-05, 'epoch': 0.6385642737896494}
2025-07-21 12:14:25,199 - __main__ - INFO - Step 7700: {'loss': 0.3186, 'grad_norm': 1.5848292112350464, 'learning_rate': 3.929187534780189e-05, 'epoch': 0.6427378964941569}
2025-07-21 12:14:34,544 - __main__ - INFO - Step 7750: {'loss': 0.296, 'grad_norm': 1.6748857498168945, 'learning_rate': 3.922231496939343e-05, 'epoch': 0.6469115191986644}
2025-07-21 12:14:42,858 - __main__ - INFO - Step 7800: {'loss': 0.2854, 'grad_norm': 2.2611918449401855, 'learning_rate': 3.9152754590984974e-05, 'epoch': 0.6510851419031719}
2025-07-21 12:14:53,394 - __main__ - INFO - Step 7850: {'loss': 0.3123, 'grad_norm': 1.3257073163986206, 'learning_rate': 3.908319421257652e-05, 'epoch': 0.6552587646076795}
2025-07-21 12:15:04,888 - __main__ - INFO - Step 7900: {'loss': 0.2938, 'grad_norm': 2.182765007019043, 'learning_rate': 3.901363383416806e-05, 'epoch': 0.659432387312187}
2025-07-21 12:15:15,904 - __main__ - INFO - Step 7950: {'loss': 0.3047, 'grad_norm': 1.4018418788909912, 'learning_rate': 3.89440734557596e-05, 'epoch': 0.6636060100166945}
2025-07-21 12:15:24,439 - __main__ - INFO - Step 8000: {'loss': 0.3037, 'grad_norm': 1.5275877714157104, 'learning_rate': 3.887451307735114e-05, 'epoch': 0.667779632721202}
2025-07-21 12:15:33,796 - __main__ - INFO - Step 8050: {'loss': 0.3012, 'grad_norm': 1.7759455442428589, 'learning_rate': 3.880495269894268e-05, 'epoch': 0.6719532554257095}
2025-07-21 12:15:42,059 - __main__ - INFO - Step 8100: {'loss': 0.3013, 'grad_norm': 1.511206865310669, 'learning_rate': 3.873539232053423e-05, 'epoch': 0.676126878130217}
2025-07-21 12:15:48,023 - __main__ - INFO - Step 8150: {'loss': 0.2937, 'grad_norm': 2.0110862255096436, 'learning_rate': 3.866583194212577e-05, 'epoch': 0.6803005008347245}
2025-07-21 12:15:56,278 - __main__ - INFO - Step 8200: {'loss': 0.2809, 'grad_norm': 2.395704507827759, 'learning_rate': 3.859627156371731e-05, 'epoch': 0.6844741235392321}
2025-07-21 12:16:04,509 - __main__ - INFO - Step 8250: {'loss': 0.3046, 'grad_norm': 2.8744773864746094, 'learning_rate': 3.852671118530885e-05, 'epoch': 0.6886477462437396}
2025-07-21 12:16:12,915 - __main__ - INFO - Step 8300: {'loss': 0.2927, 'grad_norm': 1.919586420059204, 'learning_rate': 3.8457150806900396e-05, 'epoch': 0.6928213689482471}
2025-07-21 12:16:18,785 - __main__ - INFO - Step 8350: {'loss': 0.3185, 'grad_norm': 1.650148630142212, 'learning_rate': 3.838759042849193e-05, 'epoch': 0.6969949916527546}
2025-07-21 12:16:27,091 - __main__ - INFO - Step 8400: {'loss': 0.2863, 'grad_norm': 2.166663646697998, 'learning_rate': 3.8318030050083476e-05, 'epoch': 0.7011686143572621}
2025-07-21 12:16:35,453 - __main__ - INFO - Step 8450: {'loss': 0.279, 'grad_norm': 1.6052368879318237, 'learning_rate': 3.8248469671675016e-05, 'epoch': 0.7053422370617696}
2025-07-21 12:16:43,751 - __main__ - INFO - Step 8500: {'loss': 0.3004, 'grad_norm': 1.3780769109725952, 'learning_rate': 3.8178909293266556e-05, 'epoch': 0.7095158597662772}
2025-07-21 12:16:49,648 - __main__ - INFO - Step 8550: {'loss': 0.3065, 'grad_norm': 2.2526051998138428, 'learning_rate': 3.81093489148581e-05, 'epoch': 0.7136894824707847}
2025-07-21 12:16:57,910 - __main__ - INFO - Step 8600: {'loss': 0.3019, 'grad_norm': 2.1251373291015625, 'learning_rate': 3.803978853644964e-05, 'epoch': 0.7178631051752922}
2025-07-21 12:17:06,165 - __main__ - INFO - Step 8650: {'loss': 0.2913, 'grad_norm': 1.699963092803955, 'learning_rate': 3.7970228158041184e-05, 'epoch': 0.7220367278797997}
2025-07-21 12:17:14,554 - __main__ - INFO - Step 8700: {'loss': 0.2967, 'grad_norm': 1.6283340454101562, 'learning_rate': 3.790066777963272e-05, 'epoch': 0.7262103505843072}
2025-07-21 12:17:20,358 - __main__ - INFO - Step 8750: {'loss': 0.2909, 'grad_norm': 1.9213789701461792, 'learning_rate': 3.7831107401224264e-05, 'epoch': 0.7303839732888147}
2025-07-21 12:17:28,516 - __main__ - INFO - Step 8800: {'loss': 0.2925, 'grad_norm': 1.492854118347168, 'learning_rate': 3.7761547022815804e-05, 'epoch': 0.7345575959933222}
2025-07-21 12:17:36,883 - __main__ - INFO - Step 8850: {'loss': 0.3084, 'grad_norm': 1.637208104133606, 'learning_rate': 3.7691986644407344e-05, 'epoch': 0.7387312186978298}
2025-07-21 12:17:45,107 - __main__ - INFO - Step 8900: {'loss': 0.2958, 'grad_norm': 1.601624846458435, 'learning_rate': 3.762381747356706e-05, 'epoch': 0.7429048414023373}
2025-07-21 12:17:50,937 - __main__ - INFO - Step 8950: {'loss': 0.3095, 'grad_norm': 1.980007529258728, 'learning_rate': 3.75542570951586e-05, 'epoch': 0.7470784641068448}
2025-07-21 12:17:59,180 - __main__ - INFO - Step 9000: {'loss': 0.2784, 'grad_norm': 2.96614146232605, 'learning_rate': 3.748469671675014e-05, 'epoch': 0.7512520868113522}
2025-07-21 12:18:07,520 - __main__ - INFO - Step 9050: {'loss': 0.29, 'grad_norm': 1.6911795139312744, 'learning_rate': 3.7415136338341685e-05, 'epoch': 0.7554257095158597}
2025-07-21 12:18:15,837 - __main__ - INFO - Step 9100: {'loss': 0.2986, 'grad_norm': 1.534808874130249, 'learning_rate': 3.734557595993322e-05, 'epoch': 0.7595993322203672}
2025-07-21 12:18:21,721 - __main__ - INFO - Step 9150: {'loss': 0.2768, 'grad_norm': 1.9934827089309692, 'learning_rate': 3.7276015581524766e-05, 'epoch': 0.7637729549248747}
2025-07-21 12:18:29,958 - __main__ - INFO - Step 9200: {'loss': 0.3125, 'grad_norm': 1.8140933513641357, 'learning_rate': 3.7206455203116306e-05, 'epoch': 0.7679465776293823}
2025-07-21 12:18:38,360 - __main__ - INFO - Step 9250: {'loss': 0.2956, 'grad_norm': 1.8674997091293335, 'learning_rate': 3.7136894824707846e-05, 'epoch': 0.7721202003338898}
2025-07-21 12:18:46,657 - __main__ - INFO - Step 9300: {'loss': 0.2918, 'grad_norm': 1.8134119510650635, 'learning_rate': 3.706733444629939e-05, 'epoch': 0.7762938230383973}
2025-07-21 12:18:52,018 - __main__ - INFO - Step 9350: {'loss': 0.2781, 'grad_norm': 1.8612802028656006, 'learning_rate': 3.699777406789093e-05, 'epoch': 0.7804674457429048}
2025-07-21 12:19:00,168 - __main__ - INFO - Step 9400: {'loss': 0.2947, 'grad_norm': 1.789842963218689, 'learning_rate': 3.692821368948247e-05, 'epoch': 0.7846410684474123}
2025-07-21 12:19:08,568 - __main__ - INFO - Step 9450: {'loss': 0.2971, 'grad_norm': 2.09214448928833, 'learning_rate': 3.6858653311074013e-05, 'epoch': 0.7888146911519198}
2025-07-21 12:19:16,987 - __main__ - INFO - Step 9500: {'loss': 0.3073, 'grad_norm': 2.0019707679748535, 'learning_rate': 3.6789092932665554e-05, 'epoch': 0.7929883138564274}
2025-07-21 12:19:23,030 - __main__ - INFO - Step 9550: {'loss': 0.2798, 'grad_norm': 1.9733489751815796, 'learning_rate': 3.6719532554257094e-05, 'epoch': 0.7971619365609349}
2025-07-21 12:19:31,238 - __main__ - INFO - Step 9600: {'loss': 0.2959, 'grad_norm': 1.491888403892517, 'learning_rate': 3.664997217584864e-05, 'epoch': 0.8013355592654424}
2025-07-21 12:19:39,521 - __main__ - INFO - Step 9650: {'loss': 0.3149, 'grad_norm': 1.4939051866531372, 'learning_rate': 3.658041179744018e-05, 'epoch': 0.8055091819699499}
2025-07-21 12:19:47,768 - __main__ - INFO - Step 9700: {'loss': 0.3038, 'grad_norm': 2.6455581188201904, 'learning_rate': 3.651085141903172e-05, 'epoch': 0.8096828046744574}
2025-07-21 12:19:53,668 - __main__ - INFO - Step 9750: {'loss': 0.2918, 'grad_norm': 2.908546209335327, 'learning_rate': 3.644129104062327e-05, 'epoch': 0.8138564273789649}
2025-07-21 12:20:01,904 - __main__ - INFO - Step 9800: {'loss': 0.2885, 'grad_norm': 1.797934889793396, 'learning_rate': 3.63717306622148e-05, 'epoch': 0.8180300500834724}
2025-07-21 12:20:10,238 - __main__ - INFO - Step 9850: {'loss': 0.3155, 'grad_norm': 2.2335472106933594, 'learning_rate': 3.630217028380635e-05, 'epoch': 0.82220367278798}
2025-07-21 12:20:18,478 - __main__ - INFO - Step 9900: {'loss': 0.2854, 'grad_norm': 2.6803181171417236, 'learning_rate': 3.623260990539788e-05, 'epoch': 0.8263772954924875}
2025-07-21 12:20:24,357 - __main__ - INFO - Step 9950: {'loss': 0.2898, 'grad_norm': 2.622708320617676, 'learning_rate': 3.616304952698943e-05, 'epoch': 0.830550918196995}
2025-07-21 12:20:32,582 - __main__ - INFO - Step 10000: {'loss': 0.3027, 'grad_norm': 1.3991777896881104, 'learning_rate': 3.609348914858097e-05, 'epoch': 0.8347245409015025}
2025-07-21 12:20:40,949 - __main__ - INFO - Step 10050: {'loss': 0.2869, 'grad_norm': 1.6155600547790527, 'learning_rate': 3.602392877017251e-05, 'epoch': 0.83889816360601}
2025-07-21 12:20:49,181 - __main__ - INFO - Step 10100: {'loss': 0.2864, 'grad_norm': 2.0194013118743896, 'learning_rate': 3.5954368391764056e-05, 'epoch': 0.8430717863105175}
2025-07-21 12:20:55,025 - __main__ - INFO - Step 10150: {'loss': 0.2941, 'grad_norm': 1.6877028942108154, 'learning_rate': 3.588480801335559e-05, 'epoch': 0.8472454090150251}
2025-07-21 12:21:03,299 - __main__ - INFO - Step 10200: {'loss': 0.2962, 'grad_norm': 1.5317341089248657, 'learning_rate': 3.5815247634947137e-05, 'epoch': 0.8514190317195326}
2025-07-21 12:21:11,627 - __main__ - INFO - Step 10250: {'loss': 0.2982, 'grad_norm': 1.6970900297164917, 'learning_rate': 3.574568725653868e-05, 'epoch': 0.8555926544240401}
2025-07-21 12:21:19,908 - __main__ - INFO - Step 10300: {'loss': 0.2962, 'grad_norm': 1.7418544292449951, 'learning_rate': 3.567612687813022e-05, 'epoch': 0.8597662771285476}
2025-07-21 12:21:25,750 - __main__ - INFO - Step 10350: {'loss': 0.2929, 'grad_norm': 1.970605492591858, 'learning_rate': 3.5606566499721764e-05, 'epoch': 0.8639398998330551}
2025-07-21 12:21:33,985 - __main__ - INFO - Step 10400: {'loss': 0.2925, 'grad_norm': 1.8945409059524536, 'learning_rate': 3.5537006121313304e-05, 'epoch': 0.8681135225375626}
2025-07-21 12:21:42,342 - __main__ - INFO - Step 10450: {'loss': 0.2911, 'grad_norm': 1.601407527923584, 'learning_rate': 3.5467445742904844e-05, 'epoch': 0.8722871452420701}
2025-07-21 12:21:48,169 - __main__ - INFO - Step 10500: {'loss': 0.2833, 'grad_norm': 1.9317682981491089, 'learning_rate': 3.5397885364496384e-05, 'epoch': 0.8764607679465777}
2025-07-21 12:21:56,373 - __main__ - INFO - Step 10550: {'loss': 0.2834, 'grad_norm': 1.9669932126998901, 'learning_rate': 3.5328324986087925e-05, 'epoch': 0.8806343906510852}
2025-07-21 12:22:04,649 - __main__ - INFO - Step 10600: {'loss': 0.3036, 'grad_norm': 1.6843645572662354, 'learning_rate': 3.5258764607679465e-05, 'epoch': 0.8848080133555927}
2025-07-21 12:22:13,030 - __main__ - INFO - Step 10650: {'loss': 0.3011, 'grad_norm': 1.9139654636383057, 'learning_rate': 3.518920422927101e-05, 'epoch': 0.8889816360601002}
2025-07-21 12:22:18,849 - __main__ - INFO - Step 10700: {'loss': 0.2775, 'grad_norm': 1.5711350440979004, 'learning_rate': 3.511964385086255e-05, 'epoch': 0.8931552587646077}
2025-07-21 12:22:27,024 - __main__ - INFO - Step 10750: {'loss': 0.2888, 'grad_norm': 1.2880619764328003, 'learning_rate': 3.505008347245409e-05, 'epoch': 0.8973288814691152}
2025-07-21 12:22:35,326 - __main__ - INFO - Step 10800: {'loss': 0.2859, 'grad_norm': 1.49066960811615, 'learning_rate': 3.498052309404563e-05, 'epoch': 0.9015025041736227}
2025-07-21 12:22:43,612 - __main__ - INFO - Step 10850: {'loss': 0.2731, 'grad_norm': 2.6175029277801514, 'learning_rate': 3.491096271563717e-05, 'epoch': 0.9056761268781303}
2025-07-21 12:22:49,272 - __main__ - INFO - Step 10900: {'loss': 0.2865, 'grad_norm': 1.869590401649475, 'learning_rate': 3.484140233722872e-05, 'epoch': 0.9098497495826378}
2025-07-21 12:22:57,487 - __main__ - INFO - Step 10950: {'loss': 0.2829, 'grad_norm': 1.3820255994796753, 'learning_rate': 3.477184195882025e-05, 'epoch': 0.9140233722871453}
2025-07-21 12:23:05,708 - __main__ - INFO - Step 11000: {'loss': 0.283, 'grad_norm': 2.3914363384246826, 'learning_rate': 3.47022815804118e-05, 'epoch': 0.9181969949916527}
2025-07-21 12:23:14,038 - __main__ - INFO - Step 11050: {'loss': 0.2949, 'grad_norm': 1.785866141319275, 'learning_rate': 3.463272120200334e-05, 'epoch': 0.9223706176961602}
2025-07-21 12:23:20,046 - __main__ - INFO - Step 11100: {'loss': 0.2914, 'grad_norm': 1.8884027004241943, 'learning_rate': 3.456316082359488e-05, 'epoch': 0.9265442404006677}
2025-07-21 12:23:28,209 - __main__ - INFO - Step 11150: {'loss': 0.2806, 'grad_norm': 1.4921427965164185, 'learning_rate': 3.449360044518643e-05, 'epoch': 0.9307178631051753}
2025-07-21 12:23:36,573 - __main__ - INFO - Step 11200: {'loss': 0.288, 'grad_norm': 1.5562161207199097, 'learning_rate': 3.442404006677796e-05, 'epoch': 0.9348914858096828}
2025-07-21 12:23:44,790 - __main__ - INFO - Step 11250: {'loss': 0.2929, 'grad_norm': 2.1231651306152344, 'learning_rate': 3.435447968836951e-05, 'epoch': 0.9390651085141903}
2025-07-21 12:23:50,582 - __main__ - INFO - Step 11300: {'loss': 0.2992, 'grad_norm': 2.3661139011383057, 'learning_rate': 3.428491930996105e-05, 'epoch': 0.9432387312186978}
2025-07-21 12:23:58,764 - __main__ - INFO - Step 11350: {'loss': 0.3089, 'grad_norm': 1.731210470199585, 'learning_rate': 3.421535893155259e-05, 'epoch': 0.9474123539232053}
2025-07-21 12:24:07,012 - __main__ - INFO - Step 11400: {'loss': 0.2824, 'grad_norm': 1.7364670038223267, 'learning_rate': 3.4145798553144135e-05, 'epoch': 0.9515859766277128}
2025-07-21 12:24:15,299 - __main__ - INFO - Step 11450: {'loss': 0.2915, 'grad_norm': 2.3555052280426025, 'learning_rate': 3.407623817473567e-05, 'epoch': 0.9557595993322203}
2025-07-21 12:24:21,152 - __main__ - INFO - Step 11500: {'loss': 0.2818, 'grad_norm': 2.135927677154541, 'learning_rate': 3.4006677796327215e-05, 'epoch': 0.9599332220367279}
2025-07-21 12:24:29,329 - __main__ - INFO - Step 11550: {'loss': 0.2798, 'grad_norm': 1.1988534927368164, 'learning_rate': 3.3937117417918755e-05, 'epoch': 0.9641068447412354}
2025-07-21 12:24:37,720 - __main__ - INFO - Step 11600: {'loss': 0.2941, 'grad_norm': 1.6740554571151733, 'learning_rate': 3.3867557039510295e-05, 'epoch': 0.9682804674457429}
2025-07-21 12:24:45,952 - __main__ - INFO - Step 11650: {'loss': 0.2855, 'grad_norm': 2.323819160461426, 'learning_rate': 3.3797996661101836e-05, 'epoch': 0.9724540901502504}
2025-07-21 12:24:51,762 - __main__ - INFO - Step 11700: {'loss': 0.2847, 'grad_norm': 2.4858434200286865, 'learning_rate': 3.372843628269338e-05, 'epoch': 0.9766277128547579}
2025-07-21 12:24:59,975 - __main__ - INFO - Step 11750: {'loss': 0.2825, 'grad_norm': 2.066826343536377, 'learning_rate': 3.365887590428492e-05, 'epoch': 0.9808013355592654}
2025-07-21 12:25:08,264 - __main__ - INFO - Step 11800: {'loss': 0.2842, 'grad_norm': 3.0945322513580322, 'learning_rate': 3.358931552587646e-05, 'epoch': 0.9849749582637729}
2025-07-21 12:25:16,540 - __main__ - INFO - Step 11850: {'loss': 0.2693, 'grad_norm': 1.2698417901992798, 'learning_rate': 3.3519755147468e-05, 'epoch': 0.9891485809682805}
2025-07-21 12:25:22,425 - __main__ - INFO - Step 11900: {'loss': 0.2945, 'grad_norm': 2.282236337661743, 'learning_rate': 3.345019476905954e-05, 'epoch': 0.993322203672788}
2025-07-21 12:25:30,700 - __main__ - INFO - Step 11950: {'loss': 0.2748, 'grad_norm': 2.152303457260132, 'learning_rate': 3.338063439065109e-05, 'epoch': 0.9974958263772955}
2025-07-21 12:25:36,007 - __main__ - INFO - Epoch 1.0 completed in 2065.36 seconds
2025-07-21 12:26:29,726 - __main__ - INFO - Step 11980: {'eval_loss': 0.2821662724018097, 'eval_runtime': 53.6995, 'eval_samples_per_second': 1586.422, 'eval_steps_per_second': 24.805, 'epoch': 1.0}
2025-07-21 12:26:30,948 - __main__ - INFO - Starting Epoch 2.0/3
2025-07-21 12:26:34,567 - __main__ - INFO - Step 12000: {'loss': 0.2949, 'grad_norm': 1.6649171113967896, 'learning_rate': 3.3311074012242624e-05, 'epoch': 1.001669449081803}
2025-07-21 12:26:42,996 - __main__ - INFO - Step 12050: {'loss': 0.2357, 'grad_norm': 3.186518907546997, 'learning_rate': 3.324151363383417e-05, 'epoch': 1.0058430717863105}
2025-07-21 12:26:48,673 - __main__ - INFO - Step 12100: {'loss': 0.2329, 'grad_norm': 1.658118486404419, 'learning_rate': 3.317195325542571e-05, 'epoch': 1.010016694490818}
2025-07-21 12:26:56,894 - __main__ - INFO - Step 12150: {'loss': 0.2384, 'grad_norm': 2.802865982055664, 'learning_rate': 3.310239287701725e-05, 'epoch': 1.0141903171953255}
2025-07-21 12:27:05,304 - __main__ - INFO - Step 12200: {'loss': 0.2388, 'grad_norm': 1.7212774753570557, 'learning_rate': 3.30328324986088e-05, 'epoch': 1.018363939899833}
2025-07-21 12:27:13,762 - __main__ - INFO - Step 12250: {'loss': 0.2445, 'grad_norm': 2.2671878337860107, 'learning_rate': 3.296327212020033e-05, 'epoch': 1.0225375626043405}
2025-07-21 12:27:19,705 - __main__ - INFO - Step 12300: {'loss': 0.2416, 'grad_norm': 1.692521095275879, 'learning_rate': 3.289371174179188e-05, 'epoch': 1.026711185308848}
2025-07-21 12:27:27,883 - __main__ - INFO - Step 12350: {'loss': 0.2397, 'grad_norm': 3.285510778427124, 'learning_rate': 3.282415136338342e-05, 'epoch': 1.0308848080133557}
2025-07-21 12:27:36,163 - __main__ - INFO - Step 12400: {'loss': 0.2324, 'grad_norm': 2.312065839767456, 'learning_rate': 3.275459098497496e-05, 'epoch': 1.0350584307178632}
2025-07-21 12:27:44,442 - __main__ - INFO - Step 12450: {'loss': 0.2496, 'grad_norm': 2.4227797985076904, 'learning_rate': 3.2685030606566506e-05, 'epoch': 1.0392320534223707}
2025-07-21 12:27:50,396 - __main__ - INFO - Step 12500: {'loss': 0.2446, 'grad_norm': 1.9763189554214478, 'learning_rate': 3.261547022815804e-05, 'epoch': 1.0434056761268782}
2025-07-21 12:27:58,624 - __main__ - INFO - Step 12550: {'loss': 0.252, 'grad_norm': 1.8069701194763184, 'learning_rate': 3.254730105731775e-05, 'epoch': 1.0475792988313857}
2025-07-21 12:28:06,986 - __main__ - INFO - Step 12600: {'loss': 0.2511, 'grad_norm': 2.620490789413452, 'learning_rate': 3.24777406789093e-05, 'epoch': 1.0517529215358932}
2025-07-21 12:28:15,271 - __main__ - INFO - Step 12650: {'loss': 0.2238, 'grad_norm': 2.3840560913085938, 'learning_rate': 3.240818030050083e-05, 'epoch': 1.0559265442404007}
2025-07-21 12:28:21,028 - __main__ - INFO - Step 12700: {'loss': 0.249, 'grad_norm': 2.712829351425171, 'learning_rate': 3.233861992209238e-05, 'epoch': 1.0601001669449082}
2025-07-21 12:28:29,258 - __main__ - INFO - Step 12750: {'loss': 0.2348, 'grad_norm': 1.7314457893371582, 'learning_rate': 3.226905954368392e-05, 'epoch': 1.0642737896494157}
2025-07-21 12:28:37,613 - __main__ - INFO - Step 12800: {'loss': 0.2324, 'grad_norm': 1.6192340850830078, 'learning_rate': 3.219949916527546e-05, 'epoch': 1.0684474123539232}
2025-07-21 12:28:45,834 - __main__ - INFO - Step 12850: {'loss': 0.2294, 'grad_norm': 2.289799451828003, 'learning_rate': 3.2129938786867e-05, 'epoch': 1.0726210350584306}
2025-07-21 12:28:51,758 - __main__ - INFO - Step 12900: {'loss': 0.2305, 'grad_norm': 2.8456079959869385, 'learning_rate': 3.206037840845854e-05, 'epoch': 1.0767946577629381}
2025-07-21 12:29:00,015 - __main__ - INFO - Step 12950: {'loss': 0.228, 'grad_norm': 2.656280517578125, 'learning_rate': 3.199081803005009e-05, 'epoch': 1.0809682804674456}
2025-07-21 12:29:08,323 - __main__ - INFO - Step 13000: {'loss': 0.237, 'grad_norm': 3.1935980319976807, 'learning_rate': 3.192125765164163e-05, 'epoch': 1.0851419031719534}
2025-07-21 12:29:16,537 - __main__ - INFO - Step 13050: {'loss': 0.2454, 'grad_norm': 1.7045555114746094, 'learning_rate': 3.185169727323317e-05, 'epoch': 1.0893155258764609}
2025-07-21 12:29:22,359 - __main__ - INFO - Step 13100: {'loss': 0.2412, 'grad_norm': 2.6323676109313965, 'learning_rate': 3.178213689482471e-05, 'epoch': 1.0934891485809684}
2025-07-21 12:29:30,606 - __main__ - INFO - Step 13150: {'loss': 0.2298, 'grad_norm': 2.1072096824645996, 'learning_rate': 3.171257651641625e-05, 'epoch': 1.0976627712854758}
2025-07-21 12:29:38,910 - __main__ - INFO - Step 13200: {'loss': 0.2318, 'grad_norm': 2.9322993755340576, 'learning_rate': 3.164301613800779e-05, 'epoch': 1.1018363939899833}
2025-07-21 12:29:47,170 - __main__ - INFO - Step 13250: {'loss': 0.2467, 'grad_norm': 2.258690595626831, 'learning_rate': 3.1573455759599335e-05, 'epoch': 1.1060100166944908}
2025-07-21 12:29:52,980 - __main__ - INFO - Step 13300: {'loss': 0.2318, 'grad_norm': 2.1483194828033447, 'learning_rate': 3.1503895381190876e-05, 'epoch': 1.1101836393989983}
2025-07-21 12:30:01,289 - __main__ - INFO - Step 13350: {'loss': 0.2438, 'grad_norm': 2.151639223098755, 'learning_rate': 3.1434335002782416e-05, 'epoch': 1.1143572621035058}
2025-07-21 12:30:09,604 - __main__ - INFO - Step 13400: {'loss': 0.2384, 'grad_norm': 2.289257764816284, 'learning_rate': 3.136477462437396e-05, 'epoch': 1.1185308848080133}
2025-07-21 12:30:17,825 - __main__ - INFO - Step 13450: {'loss': 0.2564, 'grad_norm': 2.186159610748291, 'learning_rate': 3.1295214245965496e-05, 'epoch': 1.1227045075125208}
2025-07-21 12:30:23,746 - __main__ - INFO - Step 13500: {'loss': 0.2347, 'grad_norm': 2.0496363639831543, 'learning_rate': 3.122565386755704e-05, 'epoch': 1.1268781302170283}
2025-07-21 12:30:32,021 - __main__ - INFO - Step 13550: {'loss': 0.2233, 'grad_norm': 2.1758158206939697, 'learning_rate': 3.115609348914858e-05, 'epoch': 1.1310517529215358}
2025-07-21 12:30:40,352 - __main__ - INFO - Step 13600: {'loss': 0.2291, 'grad_norm': 2.7519216537475586, 'learning_rate': 3.1086533110740123e-05, 'epoch': 1.1352253756260433}
2025-07-21 12:30:48,553 - __main__ - INFO - Step 13650: {'loss': 0.2372, 'grad_norm': 2.040419816970825, 'learning_rate': 3.101697273233167e-05, 'epoch': 1.139398998330551}
2025-07-21 12:30:54,498 - __main__ - INFO - Step 13700: {'loss': 0.2297, 'grad_norm': 1.7899564504623413, 'learning_rate': 3.0947412353923204e-05, 'epoch': 1.1435726210350585}
2025-07-21 12:31:02,819 - __main__ - INFO - Step 13750: {'loss': 0.2291, 'grad_norm': 1.469860553741455, 'learning_rate': 3.087785197551475e-05, 'epoch': 1.147746243739566}
2025-07-21 12:31:11,133 - __main__ - INFO - Step 13800: {'loss': 0.234, 'grad_norm': 1.93832528591156, 'learning_rate': 3.080829159710629e-05, 'epoch': 1.1519198664440735}
2025-07-21 12:31:16,882 - __main__ - INFO - Step 13850: {'loss': 0.2308, 'grad_norm': 2.6569089889526367, 'learning_rate': 3.073873121869783e-05, 'epoch': 1.156093489148581}
2025-07-21 12:31:25,103 - __main__ - INFO - Step 13900: {'loss': 0.2207, 'grad_norm': 2.6527280807495117, 'learning_rate': 3.066917084028937e-05, 'epoch': 1.1602671118530885}
2025-07-21 12:31:33,389 - __main__ - INFO - Step 13950: {'loss': 0.2346, 'grad_norm': 1.762904405593872, 'learning_rate': 3.059961046188091e-05, 'epoch': 1.164440734557596}
2025-07-21 12:31:41,688 - __main__ - INFO - Step 14000: {'loss': 0.2188, 'grad_norm': 3.8593385219573975, 'learning_rate': 3.053005008347246e-05, 'epoch': 1.1686143572621035}
2025-07-21 12:31:47,579 - __main__ - INFO - Step 14050: {'loss': 0.244, 'grad_norm': 3.7477598190307617, 'learning_rate': 3.0460489705064e-05, 'epoch': 1.172787979966611}
2025-07-21 12:31:55,839 - __main__ - INFO - Step 14100: {'loss': 0.2352, 'grad_norm': 1.8012422323226929, 'learning_rate': 3.039092932665554e-05, 'epoch': 1.1769616026711185}
2025-07-21 12:32:04,122 - __main__ - INFO - Step 14150: {'loss': 0.2398, 'grad_norm': 2.8483262062072754, 'learning_rate': 3.0321368948247082e-05, 'epoch': 1.181135225375626}
2025-07-21 12:32:12,536 - __main__ - INFO - Step 14200: {'loss': 0.2229, 'grad_norm': 1.7468807697296143, 'learning_rate': 3.025180856983862e-05, 'epoch': 1.1853088480801335}
2025-07-21 12:32:18,453 - __main__ - INFO - Step 14250: {'loss': 0.2219, 'grad_norm': 2.3524246215820312, 'learning_rate': 3.0182248191430163e-05, 'epoch': 1.189482470784641}
2025-07-21 12:32:26,733 - __main__ - INFO - Step 14300: {'loss': 0.2391, 'grad_norm': 2.157233953475952, 'learning_rate': 3.0112687813021706e-05, 'epoch': 1.1936560934891487}
2025-07-21 12:32:35,067 - __main__ - INFO - Step 14350: {'loss': 0.2585, 'grad_norm': 1.6331888437271118, 'learning_rate': 3.0043127434613243e-05, 'epoch': 1.197829716193656}
2025-07-21 12:32:43,406 - __main__ - INFO - Step 14400: {'loss': 0.2425, 'grad_norm': 1.9925472736358643, 'learning_rate': 2.9973567056204787e-05, 'epoch': 1.2020033388981637}
2025-07-21 12:32:49,240 - __main__ - INFO - Step 14450: {'loss': 0.2474, 'grad_norm': 2.1335225105285645, 'learning_rate': 2.990400667779633e-05, 'epoch': 1.2061769616026712}
2025-07-21 12:32:57,479 - __main__ - INFO - Step 14500: {'loss': 0.2459, 'grad_norm': 1.8921018838882446, 'learning_rate': 2.983444629938787e-05, 'epoch': 1.2103505843071787}
2025-07-21 12:33:05,809 - __main__ - INFO - Step 14550: {'loss': 0.2351, 'grad_norm': 2.0404281616210938, 'learning_rate': 2.9764885920979414e-05, 'epoch': 1.2145242070116862}
2025-07-21 12:33:14,056 - __main__ - INFO - Step 14600: {'loss': 0.2394, 'grad_norm': 1.7726742029190063, 'learning_rate': 2.969532554257095e-05, 'epoch': 1.2186978297161937}
2025-07-21 12:33:19,962 - __main__ - INFO - Step 14650: {'loss': 0.2417, 'grad_norm': 3.207185983657837, 'learning_rate': 2.9625765164162494e-05, 'epoch': 1.2228714524207012}
2025-07-21 12:33:28,241 - __main__ - INFO - Step 14700: {'loss': 0.2441, 'grad_norm': 3.2889676094055176, 'learning_rate': 2.9556204785754038e-05, 'epoch': 1.2270450751252087}
2025-07-21 12:33:36,517 - __main__ - INFO - Step 14750: {'loss': 0.2422, 'grad_norm': 2.2239365577697754, 'learning_rate': 2.9486644407345575e-05, 'epoch': 1.2312186978297162}
2025-07-21 12:33:44,856 - __main__ - INFO - Step 14800: {'loss': 0.2496, 'grad_norm': 3.073279619216919, 'learning_rate': 2.941708402893712e-05, 'epoch': 1.2353923205342237}
2025-07-21 12:33:50,732 - __main__ - INFO - Step 14850: {'loss': 0.2359, 'grad_norm': 3.1898953914642334, 'learning_rate': 2.934752365052866e-05, 'epoch': 1.2395659432387311}
2025-07-21 12:33:58,970 - __main__ - INFO - Step 14900: {'loss': 0.2141, 'grad_norm': 2.1786134243011475, 'learning_rate': 2.9277963272120202e-05, 'epoch': 1.2437395659432386}
2025-07-21 12:34:07,323 - __main__ - INFO - Step 14950: {'loss': 0.2337, 'grad_norm': 2.0699610710144043, 'learning_rate': 2.9208402893711746e-05, 'epoch': 1.2479131886477464}
2025-07-21 12:34:15,555 - __main__ - INFO - Step 15000: {'loss': 0.2354, 'grad_norm': 2.8251609802246094, 'learning_rate': 2.9138842515303282e-05, 'epoch': 1.2520868113522536}
2025-07-21 12:34:21,423 - __main__ - INFO - Step 15050: {'loss': 0.2264, 'grad_norm': 2.0261070728302, 'learning_rate': 2.9069282136894826e-05, 'epoch': 1.2562604340567614}
2025-07-21 12:34:29,678 - __main__ - INFO - Step 15100: {'loss': 0.2444, 'grad_norm': 1.936820387840271, 'learning_rate': 2.899972175848637e-05, 'epoch': 1.2604340567612689}
2025-07-21 12:34:37,983 - __main__ - INFO - Step 15150: {'loss': 0.2388, 'grad_norm': 3.1803367137908936, 'learning_rate': 2.893016138007791e-05, 'epoch': 1.2646076794657763}
2025-07-21 12:34:46,234 - __main__ - INFO - Step 15200: {'loss': 0.241, 'grad_norm': 2.3689448833465576, 'learning_rate': 2.8860601001669453e-05, 'epoch': 1.2687813021702838}
2025-07-21 12:34:52,088 - __main__ - INFO - Step 15250: {'loss': 0.2322, 'grad_norm': 2.85673451423645, 'learning_rate': 2.879104062326099e-05, 'epoch': 1.2729549248747913}
2025-07-21 12:35:00,353 - __main__ - INFO - Step 15300: {'loss': 0.2153, 'grad_norm': 3.1537301540374756, 'learning_rate': 2.8721480244852534e-05, 'epoch': 1.2771285475792988}
2025-07-21 12:35:08,672 - __main__ - INFO - Step 15350: {'loss': 0.2287, 'grad_norm': 2.0518128871917725, 'learning_rate': 2.8651919866444077e-05, 'epoch': 1.2813021702838063}
2025-07-21 12:35:16,920 - __main__ - INFO - Step 15400: {'loss': 0.2395, 'grad_norm': 3.7250874042510986, 'learning_rate': 2.8582359488035614e-05, 'epoch': 1.2854757929883138}
2025-07-21 12:35:22,676 - __main__ - INFO - Step 15450: {'loss': 0.2374, 'grad_norm': 2.4630298614501953, 'learning_rate': 2.8514190317195328e-05, 'epoch': 1.2896494156928213}
2025-07-21 12:35:30,929 - __main__ - INFO - Step 15500: {'loss': 0.237, 'grad_norm': 1.9653152227401733, 'learning_rate': 2.844462993878687e-05, 'epoch': 1.2938230383973288}
2025-07-21 12:35:39,238 - __main__ - INFO - Step 15550: {'loss': 0.2517, 'grad_norm': 1.892457127571106, 'learning_rate': 2.8375069560378408e-05, 'epoch': 1.2979966611018363}
2025-07-21 12:35:47,425 - __main__ - INFO - Step 15600: {'loss': 0.2263, 'grad_norm': 2.592683792114258, 'learning_rate': 2.830550918196995e-05, 'epoch': 1.302170283806344}
2025-07-21 12:35:53,413 - __main__ - INFO - Step 15650: {'loss': 0.2435, 'grad_norm': 2.564966917037964, 'learning_rate': 2.823594880356149e-05, 'epoch': 1.3063439065108513}
2025-07-21 12:36:01,778 - __main__ - INFO - Step 15700: {'loss': 0.2424, 'grad_norm': 2.925081968307495, 'learning_rate': 2.8166388425153035e-05, 'epoch': 1.310517529215359}
2025-07-21 12:36:10,004 - __main__ - INFO - Step 15750: {'loss': 0.228, 'grad_norm': 2.757505178451538, 'learning_rate': 2.809682804674458e-05, 'epoch': 1.3146911519198665}
2025-07-21 12:36:15,784 - __main__ - INFO - Step 15800: {'loss': 0.2403, 'grad_norm': 2.266998529434204, 'learning_rate': 2.8027267668336116e-05, 'epoch': 1.318864774624374}
2025-07-21 12:36:24,001 - __main__ - INFO - Step 15850: {'loss': 0.2365, 'grad_norm': 1.529889702796936, 'learning_rate': 2.795770728992766e-05, 'epoch': 1.3230383973288815}
2025-07-21 12:36:32,299 - __main__ - INFO - Step 15900: {'loss': 0.244, 'grad_norm': 2.405247449874878, 'learning_rate': 2.7888146911519196e-05, 'epoch': 1.327212020033389}
2025-07-21 12:36:40,572 - __main__ - INFO - Step 15950: {'loss': 0.247, 'grad_norm': 1.6998566389083862, 'learning_rate': 2.781858653311074e-05, 'epoch': 1.3313856427378965}
2025-07-21 12:36:46,457 - __main__ - INFO - Step 16000: {'loss': 0.2413, 'grad_norm': 1.9496078491210938, 'learning_rate': 2.7749026154702283e-05, 'epoch': 1.335559265442404}
2025-07-21 12:36:54,742 - __main__ - INFO - Step 16050: {'loss': 0.2316, 'grad_norm': 1.7034121751785278, 'learning_rate': 2.7679465776293823e-05, 'epoch': 1.3397328881469115}
2025-07-21 12:37:02,977 - __main__ - INFO - Step 16100: {'loss': 0.2299, 'grad_norm': 2.8010261058807373, 'learning_rate': 2.7609905397885367e-05, 'epoch': 1.343906510851419}
2025-07-21 12:37:11,244 - __main__ - INFO - Step 16150: {'loss': 0.2478, 'grad_norm': 2.1805009841918945, 'learning_rate': 2.754034501947691e-05, 'epoch': 1.3480801335559265}
2025-07-21 12:37:17,105 - __main__ - INFO - Step 16200: {'loss': 0.2137, 'grad_norm': 2.3747904300689697, 'learning_rate': 2.7470784641068447e-05, 'epoch': 1.352253756260434}
2025-07-21 12:37:25,322 - __main__ - INFO - Step 16250: {'loss': 0.2348, 'grad_norm': 1.662508487701416, 'learning_rate': 2.740122426265999e-05, 'epoch': 1.3564273789649417}
2025-07-21 12:37:33,687 - __main__ - INFO - Step 16300: {'loss': 0.2311, 'grad_norm': 2.6033570766448975, 'learning_rate': 2.733166388425153e-05, 'epoch': 1.360601001669449}
2025-07-21 12:37:41,890 - __main__ - INFO - Step 16350: {'loss': 0.23, 'grad_norm': 2.6560585498809814, 'learning_rate': 2.7262103505843075e-05, 'epoch': 1.3647746243739567}
2025-07-21 12:37:47,727 - __main__ - INFO - Step 16400: {'loss': 0.2203, 'grad_norm': 2.506162405014038, 'learning_rate': 2.7192543127434618e-05, 'epoch': 1.3689482470784642}
2025-07-21 12:37:55,962 - __main__ - INFO - Step 16450: {'loss': 0.2354, 'grad_norm': 2.17661714553833, 'learning_rate': 2.7122982749026155e-05, 'epoch': 1.3731218697829717}
2025-07-21 12:38:04,249 - __main__ - INFO - Step 16500: {'loss': 0.2394, 'grad_norm': 2.8833014965057373, 'learning_rate': 2.70534223706177e-05, 'epoch': 1.3772954924874792}
2025-07-21 12:38:12,517 - __main__ - INFO - Step 16550: {'loss': 0.2216, 'grad_norm': 3.715942144393921, 'learning_rate': 2.6983861992209235e-05, 'epoch': 1.3814691151919867}
2025-07-21 12:38:18,366 - __main__ - INFO - Step 16600: {'loss': 0.2508, 'grad_norm': 3.2136788368225098, 'learning_rate': 2.691430161380078e-05, 'epoch': 1.3856427378964942}
2025-07-21 12:38:26,605 - __main__ - INFO - Step 16650: {'loss': 0.2204, 'grad_norm': 1.5629076957702637, 'learning_rate': 2.6844741235392322e-05, 'epoch': 1.3898163606010017}
2025-07-21 12:38:35,011 - __main__ - INFO - Step 16700: {'loss': 0.2311, 'grad_norm': 2.3651628494262695, 'learning_rate': 2.6775180856983863e-05, 'epoch': 1.3939899833055092}
2025-07-21 12:38:43,234 - __main__ - INFO - Step 16750: {'loss': 0.2447, 'grad_norm': 2.742039442062378, 'learning_rate': 2.6705620478575406e-05, 'epoch': 1.3981636060100167}
2025-07-21 12:38:49,035 - __main__ - INFO - Step 16800: {'loss': 0.2514, 'grad_norm': 1.9064853191375732, 'learning_rate': 2.663606010016695e-05, 'epoch': 1.4023372287145242}
2025-07-21 12:38:57,278 - __main__ - INFO - Step 16850: {'loss': 0.2355, 'grad_norm': 4.619077682495117, 'learning_rate': 2.6566499721758486e-05, 'epoch': 1.4065108514190316}
2025-07-21 12:39:05,624 - __main__ - INFO - Step 16900: {'loss': 0.2329, 'grad_norm': 1.8979507684707642, 'learning_rate': 2.649693934335003e-05, 'epoch': 1.4106844741235394}
2025-07-21 12:39:13,862 - __main__ - INFO - Step 16950: {'loss': 0.2211, 'grad_norm': 1.953934669494629, 'learning_rate': 2.6427378964941567e-05, 'epoch': 1.4148580968280466}
2025-07-21 12:39:19,764 - __main__ - INFO - Step 17000: {'loss': 0.2416, 'grad_norm': 1.9384845495224, 'learning_rate': 2.635781858653311e-05, 'epoch': 1.4190317195325544}
2025-07-21 12:39:28,100 - __main__ - INFO - Step 17050: {'loss': 0.2431, 'grad_norm': 2.8280231952667236, 'learning_rate': 2.6288258208124654e-05, 'epoch': 1.4232053422370616}
2025-07-21 12:39:36,469 - __main__ - INFO - Step 17100: {'loss': 0.2425, 'grad_norm': 1.704795002937317, 'learning_rate': 2.6218697829716194e-05, 'epoch': 1.4273789649415694}
2025-07-21 12:39:44,772 - __main__ - INFO - Step 17150: {'loss': 0.2287, 'grad_norm': 2.363187551498413, 'learning_rate': 2.6149137451307738e-05, 'epoch': 1.4315525876460768}
2025-07-21 12:39:50,629 - __main__ - INFO - Step 17200: {'loss': 0.2415, 'grad_norm': 2.01639986038208, 'learning_rate': 2.607957707289928e-05, 'epoch': 1.4357262103505843}
2025-07-21 12:39:58,921 - __main__ - INFO - Step 17250: {'loss': 0.2583, 'grad_norm': 2.062438488006592, 'learning_rate': 2.6010016694490818e-05, 'epoch': 1.4398998330550918}
2025-07-21 12:40:07,251 - __main__ - INFO - Step 17300: {'loss': 0.2367, 'grad_norm': 2.2663419246673584, 'learning_rate': 2.594045631608236e-05, 'epoch': 1.4440734557595993}
2025-07-21 12:40:15,510 - __main__ - INFO - Step 17350: {'loss': 0.2543, 'grad_norm': 1.808976411819458, 'learning_rate': 2.5870895937673902e-05, 'epoch': 1.4482470784641068}
2025-07-21 12:40:21,471 - __main__ - INFO - Step 17400: {'loss': 0.2345, 'grad_norm': 5.816415309906006, 'learning_rate': 2.5801335559265445e-05, 'epoch': 1.4524207011686143}
2025-07-21 12:40:29,752 - __main__ - INFO - Step 17450: {'loss': 0.2225, 'grad_norm': 2.722384214401245, 'learning_rate': 2.573177518085699e-05, 'epoch': 1.4565943238731218}
2025-07-21 12:40:38,105 - __main__ - INFO - Step 17500: {'loss': 0.2329, 'grad_norm': 1.8769915103912354, 'learning_rate': 2.5662214802448526e-05, 'epoch': 1.4607679465776293}
2025-07-21 12:40:46,311 - __main__ - INFO - Step 17550: {'loss': 0.226, 'grad_norm': 1.9402284622192383, 'learning_rate': 2.559265442404007e-05, 'epoch': 1.4649415692821368}
2025-07-21 12:40:52,168 - __main__ - INFO - Step 17600: {'loss': 0.226, 'grad_norm': 2.255983829498291, 'learning_rate': 2.5523094045631606e-05, 'epoch': 1.4691151919866443}
2025-07-21 12:41:00,505 - __main__ - INFO - Step 17650: {'loss': 0.2357, 'grad_norm': 2.1303353309631348, 'learning_rate': 2.545353366722315e-05, 'epoch': 1.473288814691152}
2025-07-21 12:41:08,827 - __main__ - INFO - Step 17700: {'loss': 0.2413, 'grad_norm': 2.104766607284546, 'learning_rate': 2.5383973288814693e-05, 'epoch': 1.4774624373956593}
2025-07-21 12:41:14,627 - __main__ - INFO - Step 17750: {'loss': 0.2335, 'grad_norm': 2.8791134357452393, 'learning_rate': 2.5314412910406233e-05, 'epoch': 1.481636060100167}
2025-07-21 12:41:22,845 - __main__ - INFO - Step 17800: {'loss': 0.2275, 'grad_norm': 2.2566945552825928, 'learning_rate': 2.5244852531997777e-05, 'epoch': 1.4858096828046745}
2025-07-21 12:41:31,113 - __main__ - INFO - Step 17850: {'loss': 0.2318, 'grad_norm': 2.3957371711730957, 'learning_rate': 2.517529215358932e-05, 'epoch': 1.489983305509182}
2025-07-21 12:41:39,437 - __main__ - INFO - Step 17900: {'loss': 0.2309, 'grad_norm': 1.9226998090744019, 'learning_rate': 2.5105731775180857e-05, 'epoch': 1.4941569282136895}
2025-07-21 12:41:45,304 - __main__ - INFO - Step 17950: {'loss': 0.2439, 'grad_norm': 1.6983520984649658, 'learning_rate': 2.50361713967724e-05, 'epoch': 1.498330550918197}
2025-07-21 12:41:53,521 - __main__ - INFO - Step 18000: {'loss': 0.2248, 'grad_norm': 2.1812305450439453, 'learning_rate': 2.496661101836394e-05, 'epoch': 1.5025041736227045}
2025-07-21 12:42:01,874 - __main__ - INFO - Step 18050: {'loss': 0.2281, 'grad_norm': 2.8344359397888184, 'learning_rate': 2.489705063995548e-05, 'epoch': 1.506677796327212}
2025-07-21 12:42:10,218 - __main__ - INFO - Step 18100: {'loss': 0.2452, 'grad_norm': 3.0008385181427, 'learning_rate': 2.4827490261547025e-05, 'epoch': 1.5108514190317195}
2025-07-21 12:42:15,983 - __main__ - INFO - Step 18150: {'loss': 0.2394, 'grad_norm': 2.2330780029296875, 'learning_rate': 2.4757929883138565e-05, 'epoch': 1.515025041736227}
2025-07-21 12:42:24,214 - __main__ - INFO - Step 18200: {'loss': 0.2337, 'grad_norm': 2.4135525226593018, 'learning_rate': 2.468836950473011e-05, 'epoch': 1.5191986644407347}
2025-07-21 12:42:32,499 - __main__ - INFO - Step 18250: {'loss': 0.2464, 'grad_norm': 1.7652963399887085, 'learning_rate': 2.462020033388982e-05, 'epoch': 1.523372287145242}
2025-07-21 12:42:40,798 - __main__ - INFO - Step 18300: {'loss': 0.252, 'grad_norm': 2.23514723777771, 'learning_rate': 2.455063995548136e-05, 'epoch': 1.5275459098497497}
2025-07-21 12:42:46,694 - __main__ - INFO - Step 18350: {'loss': 0.2372, 'grad_norm': 1.7561355829238892, 'learning_rate': 2.4481079577072902e-05, 'epoch': 1.531719532554257}
2025-07-21 12:42:54,986 - __main__ - INFO - Step 18400: {'loss': 0.2379, 'grad_norm': 1.8239103555679321, 'learning_rate': 2.4411519198664443e-05, 'epoch': 1.5358931552587647}
2025-07-21 12:43:03,323 - __main__ - INFO - Step 18450: {'loss': 0.2317, 'grad_norm': 2.9605729579925537, 'learning_rate': 2.4341958820255983e-05, 'epoch': 1.540066777963272}
2025-07-21 12:43:11,616 - __main__ - INFO - Step 18500: {'loss': 0.239, 'grad_norm': 2.0709166526794434, 'learning_rate': 2.4272398441847523e-05, 'epoch': 1.5442404006677797}
2025-07-21 12:43:17,443 - __main__ - INFO - Step 18550: {'loss': 0.2503, 'grad_norm': 3.4557483196258545, 'learning_rate': 2.4202838063439067e-05, 'epoch': 1.5484140233722872}
2025-07-21 12:43:25,693 - __main__ - INFO - Step 18600: {'loss': 0.2418, 'grad_norm': 2.265747547149658, 'learning_rate': 2.413327768503061e-05, 'epoch': 1.5525876460767947}
2025-07-21 12:43:34,106 - __main__ - INFO - Step 18650: {'loss': 0.2292, 'grad_norm': 2.644307851791382, 'learning_rate': 2.406371730662215e-05, 'epoch': 1.5567612687813022}
2025-07-21 12:43:42,360 - __main__ - INFO - Step 18700: {'loss': 0.2409, 'grad_norm': 2.3804314136505127, 'learning_rate': 2.399415692821369e-05, 'epoch': 1.5609348914858097}
2025-07-21 12:43:48,200 - __main__ - INFO - Step 18750: {'loss': 0.242, 'grad_norm': 1.7568378448486328, 'learning_rate': 2.392459654980523e-05, 'epoch': 1.5651085141903172}
2025-07-21 12:43:56,494 - __main__ - INFO - Step 18800: {'loss': 0.2289, 'grad_norm': 1.9319837093353271, 'learning_rate': 2.3855036171396774e-05, 'epoch': 1.5692821368948247}
2025-07-21 12:44:04,868 - __main__ - INFO - Step 18850: {'loss': 0.2452, 'grad_norm': 2.438184976577759, 'learning_rate': 2.3785475792988314e-05, 'epoch': 1.5734557595993324}
2025-07-21 12:44:13,106 - __main__ - INFO - Step 18900: {'loss': 0.233, 'grad_norm': 1.5176661014556885, 'learning_rate': 2.3715915414579855e-05, 'epoch': 1.5776293823038396}
2025-07-21 12:44:18,935 - __main__ - INFO - Step 18950: {'loss': 0.2327, 'grad_norm': 2.2989349365234375, 'learning_rate': 2.3646355036171398e-05, 'epoch': 1.5818030050083474}
2025-07-21 12:44:27,207 - __main__ - INFO - Step 19000: {'loss': 0.2311, 'grad_norm': 1.6146937608718872, 'learning_rate': 2.3576794657762942e-05, 'epoch': 1.5859766277128546}
2025-07-21 12:44:35,613 - __main__ - INFO - Step 19050: {'loss': 0.2259, 'grad_norm': 2.2551157474517822, 'learning_rate': 2.3507234279354482e-05, 'epoch': 1.5901502504173624}
2025-07-21 12:44:43,920 - __main__ - INFO - Step 19100: {'loss': 0.2553, 'grad_norm': 2.582005500793457, 'learning_rate': 2.3437673900946022e-05, 'epoch': 1.5943238731218696}
2025-07-21 12:44:49,727 - __main__ - INFO - Step 19150: {'loss': 0.2271, 'grad_norm': 1.9668858051300049, 'learning_rate': 2.3368113522537562e-05, 'epoch': 1.5984974958263773}
2025-07-21 12:44:58,097 - __main__ - INFO - Step 19200: {'loss': 0.2258, 'grad_norm': 2.8540432453155518, 'learning_rate': 2.3298553144129103e-05, 'epoch': 1.6026711185308848}
2025-07-21 12:45:06,544 - __main__ - INFO - Step 19250: {'loss': 0.243, 'grad_norm': 2.016878366470337, 'learning_rate': 2.3228992765720646e-05, 'epoch': 1.6068447412353923}
2025-07-21 12:45:14,822 - __main__ - INFO - Step 19300: {'loss': 0.2449, 'grad_norm': 2.2024824619293213, 'learning_rate': 2.315943238731219e-05, 'epoch': 1.6110183639398998}
2025-07-21 12:45:20,708 - __main__ - INFO - Step 19350: {'loss': 0.2436, 'grad_norm': 2.4703195095062256, 'learning_rate': 2.308987200890373e-05, 'epoch': 1.6151919866444073}
2025-07-21 12:45:28,978 - __main__ - INFO - Step 19400: {'loss': 0.2166, 'grad_norm': 2.5405027866363525, 'learning_rate': 2.302031163049527e-05, 'epoch': 1.6193656093489148}
2025-07-21 12:45:37,292 - __main__ - INFO - Step 19450: {'loss': 0.243, 'grad_norm': 2.881763458251953, 'learning_rate': 2.2950751252086814e-05, 'epoch': 1.6235392320534223}
2025-07-21 12:45:45,601 - __main__ - INFO - Step 19500: {'loss': 0.2532, 'grad_norm': 2.3000917434692383, 'learning_rate': 2.2881190873678354e-05, 'epoch': 1.62771285475793}
2025-07-21 12:45:51,475 - __main__ - INFO - Step 19550: {'loss': 0.2257, 'grad_norm': 2.2978591918945312, 'learning_rate': 2.2811630495269894e-05, 'epoch': 1.6318864774624373}
2025-07-21 12:45:59,877 - __main__ - INFO - Step 19600: {'loss': 0.2328, 'grad_norm': 2.286311149597168, 'learning_rate': 2.2742070116861438e-05, 'epoch': 1.636060100166945}
2025-07-21 12:46:08,224 - __main__ - INFO - Step 19650: {'loss': 0.2465, 'grad_norm': 2.446754217147827, 'learning_rate': 2.267250973845298e-05, 'epoch': 1.6402337228714523}
2025-07-21 12:46:14,125 - __main__ - INFO - Step 19700: {'loss': 0.2364, 'grad_norm': 1.6329139471054077, 'learning_rate': 2.260294936004452e-05, 'epoch': 1.64440734557596}
2025-07-21 12:46:22,339 - __main__ - INFO - Step 19750: {'loss': 0.2221, 'grad_norm': 2.8386354446411133, 'learning_rate': 2.253338898163606e-05, 'epoch': 1.6485809682804673}
2025-07-21 12:46:30,812 - __main__ - INFO - Step 19800: {'loss': 0.2322, 'grad_norm': 2.2501864433288574, 'learning_rate': 2.24638286032276e-05, 'epoch': 1.652754590984975}
2025-07-21 12:46:39,220 - __main__ - INFO - Step 19850: {'loss': 0.2333, 'grad_norm': 3.4675259590148926, 'learning_rate': 2.2394268224819145e-05, 'epoch': 1.6569282136894825}
2025-07-21 12:46:45,032 - __main__ - INFO - Step 19900: {'loss': 0.2439, 'grad_norm': 2.2634823322296143, 'learning_rate': 2.2324707846410685e-05, 'epoch': 1.66110183639399}
2025-07-21 12:46:53,335 - __main__ - INFO - Step 19950: {'loss': 0.2215, 'grad_norm': 2.5040273666381836, 'learning_rate': 2.2255147468002226e-05, 'epoch': 1.6652754590984975}
2025-07-21 12:47:01,674 - __main__ - INFO - Step 20000: {'loss': 0.2254, 'grad_norm': 2.754453659057617, 'learning_rate': 2.218558708959377e-05, 'epoch': 1.669449081803005}
2025-07-21 12:47:09,927 - __main__ - INFO - Step 20050: {'loss': 0.2545, 'grad_norm': 2.162187337875366, 'learning_rate': 2.211602671118531e-05, 'epoch': 1.6736227045075125}
2025-07-21 12:47:15,837 - __main__ - INFO - Step 20100: {'loss': 0.2492, 'grad_norm': 2.276355504989624, 'learning_rate': 2.2046466332776853e-05, 'epoch': 1.67779632721202}
2025-07-21 12:47:24,134 - __main__ - INFO - Step 20150: {'loss': 0.2405, 'grad_norm': 1.6323506832122803, 'learning_rate': 2.1976905954368393e-05, 'epoch': 1.6819699499165277}
2025-07-21 12:47:32,467 - __main__ - INFO - Step 20200: {'loss': 0.2293, 'grad_norm': 2.4507453441619873, 'learning_rate': 2.1907345575959933e-05, 'epoch': 1.686143572621035}
2025-07-21 12:47:40,741 - __main__ - INFO - Step 20250: {'loss': 0.2364, 'grad_norm': 2.5408215522766113, 'learning_rate': 2.1837785197551473e-05, 'epoch': 1.6903171953255427}
2025-07-21 12:47:46,580 - __main__ - INFO - Step 20300: {'loss': 0.2187, 'grad_norm': 2.4259932041168213, 'learning_rate': 2.1768224819143017e-05, 'epoch': 1.69449081803005}
2025-07-21 12:47:54,810 - __main__ - INFO - Step 20350: {'loss': 0.2249, 'grad_norm': 2.12727689743042, 'learning_rate': 2.169866444073456e-05, 'epoch': 1.6986644407345577}
2025-07-21 12:48:03,153 - __main__ - INFO - Step 20400: {'loss': 0.246, 'grad_norm': 4.094364166259766, 'learning_rate': 2.16291040623261e-05, 'epoch': 1.702838063439065}
2025-07-21 12:48:11,455 - __main__ - INFO - Step 20450: {'loss': 0.2316, 'grad_norm': 2.853027582168579, 'learning_rate': 2.155954368391764e-05, 'epoch': 1.7070116861435727}
2025-07-21 12:48:17,234 - __main__ - INFO - Step 20500: {'loss': 0.2389, 'grad_norm': 1.8523889780044556, 'learning_rate': 2.1489983305509185e-05, 'epoch': 1.7111853088480802}
2025-07-21 12:48:25,500 - __main__ - INFO - Step 20550: {'loss': 0.2598, 'grad_norm': 2.9654102325439453, 'learning_rate': 2.1420422927100725e-05, 'epoch': 1.7153589315525877}
2025-07-21 12:48:33,962 - __main__ - INFO - Step 20600: {'loss': 0.2301, 'grad_norm': 1.2091546058654785, 'learning_rate': 2.1350862548692265e-05, 'epoch': 1.7195325542570952}
2025-07-21 12:48:42,192 - __main__ - INFO - Step 20650: {'loss': 0.2405, 'grad_norm': 3.452394485473633, 'learning_rate': 2.1281302170283805e-05, 'epoch': 1.7237061769616027}
2025-07-21 12:48:48,077 - __main__ - INFO - Step 20700: {'loss': 0.2234, 'grad_norm': 2.0581250190734863, 'learning_rate': 2.121174179187535e-05, 'epoch': 1.7278797996661102}
2025-07-21 12:48:56,431 - __main__ - INFO - Step 20750: {'loss': 0.2294, 'grad_norm': 2.4895191192626953, 'learning_rate': 2.1142181413466892e-05, 'epoch': 1.7320534223706177}
2025-07-21 12:49:04,808 - __main__ - INFO - Step 20800: {'loss': 0.2353, 'grad_norm': 3.024346351623535, 'learning_rate': 2.1072621035058432e-05, 'epoch': 1.7362270450751254}
2025-07-21 12:49:13,138 - __main__ - INFO - Step 20850: {'loss': 0.2187, 'grad_norm': 2.05373477935791, 'learning_rate': 2.1003060656649973e-05, 'epoch': 1.7404006677796326}
2025-07-21 12:49:18,925 - __main__ - INFO - Step 20900: {'loss': 0.2289, 'grad_norm': 2.9847869873046875, 'learning_rate': 2.0933500278241513e-05, 'epoch': 1.7445742904841404}
2025-07-21 12:49:27,193 - __main__ - INFO - Step 20950: {'loss': 0.238, 'grad_norm': 2.4956912994384766, 'learning_rate': 2.0863939899833056e-05, 'epoch': 1.7487479131886476}
2025-07-21 12:49:35,573 - __main__ - INFO - Step 21000: {'loss': 0.2521, 'grad_norm': 1.7287200689315796, 'learning_rate': 2.0794379521424596e-05, 'epoch': 1.7529215358931554}
2025-07-21 12:49:43,836 - __main__ - INFO - Step 21050: {'loss': 0.225, 'grad_norm': 1.9318784475326538, 'learning_rate': 2.072481914301614e-05, 'epoch': 1.7570951585976626}
2025-07-21 12:49:49,713 - __main__ - INFO - Step 21100: {'loss': 0.2276, 'grad_norm': 2.7606253623962402, 'learning_rate': 2.065525876460768e-05, 'epoch': 1.7612687813021703}
2025-07-21 12:49:58,008 - __main__ - INFO - Step 21150: {'loss': 0.2397, 'grad_norm': 2.715441942214966, 'learning_rate': 2.0585698386199224e-05, 'epoch': 1.7654424040066778}
2025-07-21 12:50:06,420 - __main__ - INFO - Step 21200: {'loss': 0.2261, 'grad_norm': 2.3344905376434326, 'learning_rate': 2.0516138007790764e-05, 'epoch': 1.7696160267111853}
2025-07-21 12:50:14,661 - __main__ - INFO - Step 21250: {'loss': 0.2542, 'grad_norm': 2.3710663318634033, 'learning_rate': 2.0446577629382304e-05, 'epoch': 1.7737896494156928}
2025-07-21 12:50:20,518 - __main__ - INFO - Step 21300: {'loss': 0.2367, 'grad_norm': 2.6913273334503174, 'learning_rate': 2.0377017250973844e-05, 'epoch': 1.7779632721202003}
2025-07-21 12:50:28,857 - __main__ - INFO - Step 21350: {'loss': 0.2246, 'grad_norm': 1.2354012727737427, 'learning_rate': 2.0307456872565388e-05, 'epoch': 1.7821368948247078}
2025-07-21 12:50:37,155 - __main__ - INFO - Step 21400: {'loss': 0.2193, 'grad_norm': 2.403275728225708, 'learning_rate': 2.023789649415693e-05, 'epoch': 1.7863105175292153}
2025-07-21 12:50:42,976 - __main__ - INFO - Step 21450: {'loss': 0.2519, 'grad_norm': 3.286127805709839, 'learning_rate': 2.016833611574847e-05, 'epoch': 1.7904841402337228}
2025-07-21 12:50:51,222 - __main__ - INFO - Step 21500: {'loss': 0.2362, 'grad_norm': 1.7590209245681763, 'learning_rate': 2.0098775737340012e-05, 'epoch': 1.7946577629382303}
2025-07-21 12:50:59,545 - __main__ - INFO - Step 21550: {'loss': 0.2233, 'grad_norm': 2.745898485183716, 'learning_rate': 2.0029215358931552e-05, 'epoch': 1.798831385642738}
2025-07-21 12:51:07,926 - __main__ - INFO - Step 21600: {'loss': 0.2281, 'grad_norm': 2.1085667610168457, 'learning_rate': 1.9959654980523096e-05, 'epoch': 1.8030050083472453}
2025-07-21 12:51:13,754 - __main__ - INFO - Step 21650: {'loss': 0.2336, 'grad_norm': 1.2764976024627686, 'learning_rate': 1.9890094602114636e-05, 'epoch': 1.807178631051753}
2025-07-21 12:51:21,989 - __main__ - INFO - Step 21700: {'loss': 0.2383, 'grad_norm': 3.3309736251831055, 'learning_rate': 1.9820534223706176e-05, 'epoch': 1.8113522537562603}
2025-07-21 12:51:30,394 - __main__ - INFO - Step 21750: {'loss': 0.2362, 'grad_norm': 1.696045994758606, 'learning_rate': 1.975097384529772e-05, 'epoch': 1.815525876460768}
2025-07-21 12:51:38,712 - __main__ - INFO - Step 21800: {'loss': 0.2255, 'grad_norm': 1.621046781539917, 'learning_rate': 1.9681413466889263e-05, 'epoch': 1.8196994991652755}
2025-07-21 12:51:44,503 - __main__ - INFO - Step 21850: {'loss': 0.2343, 'grad_norm': 2.3861472606658936, 'learning_rate': 1.9613244296048973e-05, 'epoch': 1.823873121869783}
2025-07-21 12:51:52,752 - __main__ - INFO - Step 21900: {'loss': 0.2194, 'grad_norm': 2.6926217079162598, 'learning_rate': 1.9543683917640513e-05, 'epoch': 1.8280467445742905}
2025-07-21 12:52:01,088 - __main__ - INFO - Step 21950: {'loss': 0.2463, 'grad_norm': 2.9943575859069824, 'learning_rate': 1.9474123539232054e-05, 'epoch': 1.832220367278798}
2025-07-21 12:52:09,425 - __main__ - INFO - Step 22000: {'loss': 0.2287, 'grad_norm': 2.576690196990967, 'learning_rate': 1.9404563160823597e-05, 'epoch': 1.8363939899833055}
2025-07-21 12:52:15,301 - __main__ - INFO - Step 22050: {'loss': 0.2377, 'grad_norm': 2.5851211547851562, 'learning_rate': 1.9335002782415137e-05, 'epoch': 1.840567612687813}
2025-07-21 12:52:23,503 - __main__ - INFO - Step 22100: {'loss': 0.2293, 'grad_norm': 2.8240482807159424, 'learning_rate': 1.9265442404006677e-05, 'epoch': 1.8447412353923205}
2025-07-21 12:52:31,898 - __main__ - INFO - Step 22150: {'loss': 0.2265, 'grad_norm': 1.845138669013977, 'learning_rate': 1.9195882025598218e-05, 'epoch': 1.848914858096828}
2025-07-21 12:52:40,197 - __main__ - INFO - Step 22200: {'loss': 0.2213, 'grad_norm': 3.30770206451416, 'learning_rate': 1.912632164718976e-05, 'epoch': 1.8530884808013357}
2025-07-21 12:52:46,012 - __main__ - INFO - Step 22250: {'loss': 0.2341, 'grad_norm': 2.7301206588745117, 'learning_rate': 1.9056761268781305e-05, 'epoch': 1.857262103505843}
2025-07-21 12:52:54,224 - __main__ - INFO - Step 22300: {'loss': 0.2452, 'grad_norm': 2.6873064041137695, 'learning_rate': 1.8987200890372845e-05, 'epoch': 1.8614357262103507}
2025-07-21 12:53:02,569 - __main__ - INFO - Step 22350: {'loss': 0.2346, 'grad_norm': 1.9154421091079712, 'learning_rate': 1.8917640511964385e-05, 'epoch': 1.865609348914858}
2025-07-21 12:53:10,889 - __main__ - INFO - Step 22400: {'loss': 0.2353, 'grad_norm': 2.9845311641693115, 'learning_rate': 1.884808013355593e-05, 'epoch': 1.8697829716193657}
2025-07-21 12:53:16,775 - __main__ - INFO - Step 22450: {'loss': 0.2456, 'grad_norm': 2.579554557800293, 'learning_rate': 1.877851975514747e-05, 'epoch': 1.873956594323873}
2025-07-21 12:53:25,034 - __main__ - INFO - Step 22500: {'loss': 0.2414, 'grad_norm': 2.2262721061706543, 'learning_rate': 1.870895937673901e-05, 'epoch': 1.8781302170283807}
2025-07-21 12:53:33,466 - __main__ - INFO - Step 22550: {'loss': 0.2298, 'grad_norm': 2.267176628112793, 'learning_rate': 1.8639398998330553e-05, 'epoch': 1.8823038397328882}
2025-07-21 12:53:41,739 - __main__ - INFO - Step 22600: {'loss': 0.2235, 'grad_norm': 1.3712821006774902, 'learning_rate': 1.8569838619922093e-05, 'epoch': 1.8864774624373957}
2025-07-21 12:53:47,566 - __main__ - INFO - Step 22650: {'loss': 0.2453, 'grad_norm': 1.866747498512268, 'learning_rate': 1.8500278241513636e-05, 'epoch': 1.8906510851419032}
2025-07-21 12:53:55,868 - __main__ - INFO - Step 22700: {'loss': 0.2315, 'grad_norm': 2.8014743328094482, 'learning_rate': 1.8430717863105177e-05, 'epoch': 1.8948247078464107}
2025-07-21 12:54:04,263 - __main__ - INFO - Step 22750: {'loss': 0.227, 'grad_norm': 2.732149600982666, 'learning_rate': 1.8361157484696717e-05, 'epoch': 1.8989983305509182}
2025-07-21 12:54:12,534 - __main__ - INFO - Step 22800: {'loss': 0.2373, 'grad_norm': 2.46885347366333, 'learning_rate': 1.8291597106288257e-05, 'epoch': 1.9031719532554257}
2025-07-21 12:54:18,465 - __main__ - INFO - Step 22850: {'loss': 0.2137, 'grad_norm': 1.8976554870605469, 'learning_rate': 1.82220367278798e-05, 'epoch': 1.9073455759599334}
2025-07-21 12:54:26,850 - __main__ - INFO - Step 22900: {'loss': 0.2393, 'grad_norm': 2.222560167312622, 'learning_rate': 1.815247634947134e-05, 'epoch': 1.9115191986644406}
2025-07-21 12:54:35,207 - __main__ - INFO - Step 22950: {'loss': 0.23, 'grad_norm': 2.1669321060180664, 'learning_rate': 1.8082915971062884e-05, 'epoch': 1.9156928213689484}
2025-07-21 12:54:43,511 - __main__ - INFO - Step 23000: {'loss': 0.2403, 'grad_norm': 2.7102718353271484, 'learning_rate': 1.8013355592654424e-05, 'epoch': 1.9198664440734556}
2025-07-21 12:54:49,387 - __main__ - INFO - Step 23050: {'loss': 0.2201, 'grad_norm': 2.3423941135406494, 'learning_rate': 1.7943795214245968e-05, 'epoch': 1.9240400667779634}
2025-07-21 12:54:57,686 - __main__ - INFO - Step 23100: {'loss': 0.2212, 'grad_norm': 5.244210243225098, 'learning_rate': 1.7874234835837508e-05, 'epoch': 1.9282136894824706}
2025-07-21 12:55:06,068 - __main__ - INFO - Step 23150: {'loss': 0.2414, 'grad_norm': 3.0680036544799805, 'learning_rate': 1.780467445742905e-05, 'epoch': 1.9323873121869783}
2025-07-21 12:55:14,339 - __main__ - INFO - Step 23200: {'loss': 0.2291, 'grad_norm': 2.572998523712158, 'learning_rate': 1.773511407902059e-05, 'epoch': 1.9365609348914858}
2025-07-21 12:55:20,173 - __main__ - INFO - Step 23250: {'loss': 0.234, 'grad_norm': 1.8735326528549194, 'learning_rate': 1.7665553700612132e-05, 'epoch': 1.9407345575959933}
2025-07-21 12:55:28,577 - __main__ - INFO - Step 23300: {'loss': 0.229, 'grad_norm': 2.5078978538513184, 'learning_rate': 1.7595993322203676e-05, 'epoch': 1.9449081803005008}
2025-07-21 12:55:36,967 - __main__ - INFO - Step 23350: {'loss': 0.2109, 'grad_norm': 2.428406000137329, 'learning_rate': 1.7526432943795216e-05, 'epoch': 1.9490818030050083}
2025-07-21 12:55:42,807 - __main__ - INFO - Step 23400: {'loss': 0.2334, 'grad_norm': 1.8977781534194946, 'learning_rate': 1.7456872565386756e-05, 'epoch': 1.9532554257095158}
2025-07-21 12:55:51,018 - __main__ - INFO - Step 23450: {'loss': 0.2478, 'grad_norm': 2.2075483798980713, 'learning_rate': 1.7387312186978296e-05, 'epoch': 1.9574290484140233}
2025-07-21 12:55:59,374 - __main__ - INFO - Step 23500: {'loss': 0.2192, 'grad_norm': 3.517094373703003, 'learning_rate': 1.731775180856984e-05, 'epoch': 1.961602671118531}
2025-07-21 12:56:07,762 - __main__ - INFO - Step 23550: {'loss': 0.2188, 'grad_norm': 2.691802501678467, 'learning_rate': 1.724819143016138e-05, 'epoch': 1.9657762938230383}
2025-07-21 12:56:13,660 - __main__ - INFO - Step 23600: {'loss': 0.2451, 'grad_norm': 1.9826751947402954, 'learning_rate': 1.7178631051752924e-05, 'epoch': 1.969949916527546}
2025-07-21 12:56:21,915 - __main__ - INFO - Step 23650: {'loss': 0.225, 'grad_norm': 3.0668580532073975, 'learning_rate': 1.7109070673344464e-05, 'epoch': 1.9741235392320533}
2025-07-21 12:56:30,301 - __main__ - INFO - Step 23700: {'loss': 0.2464, 'grad_norm': 2.7192039489746094, 'learning_rate': 1.7039510294936007e-05, 'epoch': 1.978297161936561}
2025-07-21 12:56:38,550 - __main__ - INFO - Step 23750: {'loss': 0.2348, 'grad_norm': 1.6244536638259888, 'learning_rate': 1.6969949916527548e-05, 'epoch': 1.9824707846410683}
2025-07-21 12:56:44,445 - __main__ - INFO - Step 23800: {'loss': 0.2427, 'grad_norm': 1.8429096937179565, 'learning_rate': 1.6900389538119088e-05, 'epoch': 1.986644407345576}
2025-07-21 12:56:52,731 - __main__ - INFO - Step 23850: {'loss': 0.2294, 'grad_norm': 1.9390214681625366, 'learning_rate': 1.6830829159710628e-05, 'epoch': 1.9908180300500835}
2025-07-21 12:57:01,090 - __main__ - INFO - Step 23900: {'loss': 0.2446, 'grad_norm': 1.5357666015625, 'learning_rate': 1.676126878130217e-05, 'epoch': 1.994991652754591}
2025-07-21 12:57:09,447 - __main__ - INFO - Step 23950: {'loss': 0.227, 'grad_norm': 3.0064804553985596, 'learning_rate': 1.669170840289371e-05, 'epoch': 1.9991652754590985}
2025-07-21 12:57:11,290 - __main__ - INFO - Epoch 2.0 completed in 1840.34 seconds
2025-07-21 12:58:05,608 - __main__ - INFO - Step 23960: {'eval_loss': 0.2864844501018524, 'eval_runtime': 54.3128, 'eval_samples_per_second': 1568.507, 'eval_steps_per_second': 24.525, 'epoch': 2.0}
2025-07-21 12:58:06,812 - __main__ - INFO - Starting Epoch 3.0/3
2025-07-21 12:58:13,804 - __main__ - INFO - Step 24000: {'loss': 0.1848, 'grad_norm': 3.198087692260742, 'learning_rate': 1.6622148024485255e-05, 'epoch': 2.003338898163606}
2025-07-21 12:58:19,699 - __main__ - INFO - Step 24050: {'loss': 0.1679, 'grad_norm': 3.967196226119995, 'learning_rate': 1.6553978853644965e-05, 'epoch': 2.0075125208681137}
2025-07-21 12:58:28,102 - __main__ - INFO - Step 24100: {'loss': 0.1722, 'grad_norm': 2.8630847930908203, 'learning_rate': 1.648441847523651e-05, 'epoch': 2.011686143572621}
2025-07-21 12:58:36,606 - __main__ - INFO - Step 24150: {'loss': 0.1785, 'grad_norm': 3.853034019470215, 'learning_rate': 1.641485809682805e-05, 'epoch': 2.0158597662771287}
2025-07-21 12:58:42,508 - __main__ - INFO - Step 24200: {'loss': 0.1627, 'grad_norm': 3.3281471729278564, 'learning_rate': 1.634529771841959e-05, 'epoch': 2.020033388981636}
2025-07-21 12:58:50,796 - __main__ - INFO - Step 24250: {'loss': 0.17, 'grad_norm': 1.2525640726089478, 'learning_rate': 1.627573734001113e-05, 'epoch': 2.0242070116861437}
2025-07-21 12:58:59,219 - __main__ - INFO - Step 24300: {'loss': 0.1661, 'grad_norm': 2.881255865097046, 'learning_rate': 1.6206176961602673e-05, 'epoch': 2.028380634390651}
2025-07-21 12:59:07,566 - __main__ - INFO - Step 24350: {'loss': 0.1841, 'grad_norm': 1.7939413785934448, 'learning_rate': 1.6136616583194213e-05, 'epoch': 2.0325542570951587}
2025-07-21 12:59:13,558 - __main__ - INFO - Step 24400: {'loss': 0.1744, 'grad_norm': 2.744588851928711, 'learning_rate': 1.6067056204785753e-05, 'epoch': 2.036727879799666}
2025-07-21 12:59:21,849 - __main__ - INFO - Step 24450: {'loss': 0.1629, 'grad_norm': 2.2299416065216064, 'learning_rate': 1.5997495826377297e-05, 'epoch': 2.0409015025041737}
2025-07-21 12:59:30,245 - __main__ - INFO - Step 24500: {'loss': 0.168, 'grad_norm': 4.051318168640137, 'learning_rate': 1.5927935447968837e-05, 'epoch': 2.045075125208681}
2025-07-21 12:59:38,636 - __main__ - INFO - Step 24550: {'loss': 0.1673, 'grad_norm': 4.158998966217041, 'learning_rate': 1.585837506956038e-05, 'epoch': 2.0492487479131887}
2025-07-21 12:59:44,510 - __main__ - INFO - Step 24600: {'loss': 0.1647, 'grad_norm': 1.558526635169983, 'learning_rate': 1.578881469115192e-05, 'epoch': 2.053422370617696}
2025-07-21 12:59:52,821 - __main__ - INFO - Step 24650: {'loss': 0.1712, 'grad_norm': 3.0141353607177734, 'learning_rate': 1.571925431274346e-05, 'epoch': 2.0575959933222037}
2025-07-21 13:00:01,304 - __main__ - INFO - Step 24700: {'loss': 0.1769, 'grad_norm': 3.6221823692321777, 'learning_rate': 1.5649693934335e-05, 'epoch': 2.0617696160267114}
2025-07-21 13:00:09,630 - __main__ - INFO - Step 24750: {'loss': 0.1644, 'grad_norm': 2.7881877422332764, 'learning_rate': 1.5581524763494715e-05, 'epoch': 2.0659432387312187}
2025-07-21 13:00:15,558 - __main__ - INFO - Step 24800: {'loss': 0.185, 'grad_norm': 1.6228406429290771, 'learning_rate': 1.5511964385086255e-05, 'epoch': 2.0701168614357264}
2025-07-21 13:00:23,870 - __main__ - INFO - Step 24850: {'loss': 0.1637, 'grad_norm': 3.6656394004821777, 'learning_rate': 1.5442404006677795e-05, 'epoch': 2.0742904841402336}
2025-07-21 13:00:32,201 - __main__ - INFO - Step 24900: {'loss': 0.1713, 'grad_norm': 3.5431292057037354, 'learning_rate': 1.537284362826934e-05, 'epoch': 2.0784641068447414}
2025-07-21 13:00:40,485 - __main__ - INFO - Step 24950: {'loss': 0.1773, 'grad_norm': 2.9829320907592773, 'learning_rate': 1.5303283249860882e-05, 'epoch': 2.0826377295492486}
2025-07-21 13:00:46,353 - __main__ - INFO - Step 25000: {'loss': 0.1554, 'grad_norm': 1.0500924587249756, 'learning_rate': 1.5233722871452422e-05, 'epoch': 2.0868113522537564}
2025-07-21 13:00:54,632 - __main__ - INFO - Step 25050: {'loss': 0.1543, 'grad_norm': 2.6145386695861816, 'learning_rate': 1.5164162493043963e-05, 'epoch': 2.0909849749582636}
2025-07-21 13:01:02,989 - __main__ - INFO - Step 25100: {'loss': 0.1679, 'grad_norm': 2.983830690383911, 'learning_rate': 1.5094602114635503e-05, 'epoch': 2.0951585976627713}
2025-07-21 13:01:11,250 - __main__ - INFO - Step 25150: {'loss': 0.1677, 'grad_norm': 2.5809435844421387, 'learning_rate': 1.5025041736227046e-05, 'epoch': 2.0993322203672786}
2025-07-21 13:01:17,203 - __main__ - INFO - Step 25200: {'loss': 0.1702, 'grad_norm': 3.461846113204956, 'learning_rate': 1.4955481357818588e-05, 'epoch': 2.1035058430717863}
2025-07-21 13:01:25,446 - __main__ - INFO - Step 25250: {'loss': 0.1562, 'grad_norm': 3.004765272140503, 'learning_rate': 1.4885920979410128e-05, 'epoch': 2.1076794657762936}
2025-07-21 13:01:33,789 - __main__ - INFO - Step 25300: {'loss': 0.1718, 'grad_norm': 2.694927453994751, 'learning_rate': 1.4816360601001668e-05, 'epoch': 2.1118530884808013}
2025-07-21 13:01:42,043 - __main__ - INFO - Step 25350: {'loss': 0.1682, 'grad_norm': 2.3619468212127686, 'learning_rate': 1.4746800222593212e-05, 'epoch': 2.116026711185309}
2025-07-21 13:01:47,905 - __main__ - INFO - Step 25400: {'loss': 0.1625, 'grad_norm': 2.5150859355926514, 'learning_rate': 1.4677239844184754e-05, 'epoch': 2.1202003338898163}
2025-07-21 13:01:56,181 - __main__ - INFO - Step 25450: {'loss': 0.1469, 'grad_norm': 3.556744337081909, 'learning_rate': 1.4607679465776294e-05, 'epoch': 2.124373956594324}
2025-07-21 13:02:04,502 - __main__ - INFO - Step 25500: {'loss': 0.1646, 'grad_norm': 2.4497716426849365, 'learning_rate': 1.4538119087367836e-05, 'epoch': 2.1285475792988313}
2025-07-21 13:02:12,776 - __main__ - INFO - Step 25550: {'loss': 0.1513, 'grad_norm': 3.2051303386688232, 'learning_rate': 1.446855870895938e-05, 'epoch': 2.132721202003339}
2025-07-21 13:02:18,667 - __main__ - INFO - Step 25600: {'loss': 0.1786, 'grad_norm': 2.3447909355163574, 'learning_rate': 1.439899833055092e-05, 'epoch': 2.1368948247078463}
2025-07-21 13:02:26,988 - __main__ - INFO - Step 25650: {'loss': 0.1633, 'grad_norm': 3.9711191654205322, 'learning_rate': 1.432943795214246e-05, 'epoch': 2.141068447412354}
2025-07-21 13:02:35,445 - __main__ - INFO - Step 25700: {'loss': 0.1763, 'grad_norm': 3.037301778793335, 'learning_rate': 1.4259877573734002e-05, 'epoch': 2.1452420701168613}
2025-07-21 13:02:41,349 - __main__ - INFO - Step 25750: {'loss': 0.1775, 'grad_norm': 1.421651840209961, 'learning_rate': 1.4190317195325542e-05, 'epoch': 2.149415692821369}
2025-07-21 13:02:49,596 - __main__ - INFO - Step 25800: {'loss': 0.1658, 'grad_norm': 3.7781283855438232, 'learning_rate': 1.4120756816917086e-05, 'epoch': 2.1535893155258763}
2025-07-21 13:02:57,981 - __main__ - INFO - Step 25850: {'loss': 0.1719, 'grad_norm': 3.2354328632354736, 'learning_rate': 1.4051196438508626e-05, 'epoch': 2.157762938230384}
2025-07-21 13:03:06,323 - __main__ - INFO - Step 25900: {'loss': 0.1567, 'grad_norm': 3.2959582805633545, 'learning_rate': 1.3981636060100168e-05, 'epoch': 2.1619365609348913}
2025-07-21 13:03:12,228 - __main__ - INFO - Step 25950: {'loss': 0.1777, 'grad_norm': 2.5127506256103516, 'learning_rate': 1.3912075681691708e-05, 'epoch': 2.166110183639399}
2025-07-21 13:03:20,462 - __main__ - INFO - Step 26000: {'loss': 0.1673, 'grad_norm': 2.8228461742401123, 'learning_rate': 1.3842515303283251e-05, 'epoch': 2.1702838063439067}
2025-07-21 13:03:28,722 - __main__ - INFO - Step 26050: {'loss': 0.1817, 'grad_norm': 2.118716239929199, 'learning_rate': 1.3772954924874793e-05, 'epoch': 2.174457429048414}
2025-07-21 13:03:37,085 - __main__ - INFO - Step 26100: {'loss': 0.1581, 'grad_norm': 2.483830690383911, 'learning_rate': 1.3703394546466333e-05, 'epoch': 2.1786310517529217}
2025-07-21 13:03:42,980 - __main__ - INFO - Step 26150: {'loss': 0.171, 'grad_norm': 3.7135002613067627, 'learning_rate': 1.3633834168057874e-05, 'epoch': 2.182804674457429}
2025-07-21 13:03:51,238 - __main__ - INFO - Step 26200: {'loss': 0.1736, 'grad_norm': 4.249967575073242, 'learning_rate': 1.3564273789649417e-05, 'epoch': 2.1869782971619367}
2025-07-21 13:03:59,624 - __main__ - INFO - Step 26250: {'loss': 0.1611, 'grad_norm': 4.124870777130127, 'learning_rate': 1.3494713411240959e-05, 'epoch': 2.191151919866444}
2025-07-21 13:04:07,907 - __main__ - INFO - Step 26300: {'loss': 0.1765, 'grad_norm': 4.269689083099365, 'learning_rate': 1.34251530328325e-05, 'epoch': 2.1953255425709517}
2025-07-21 13:04:13,774 - __main__ - INFO - Step 26350: {'loss': 0.1728, 'grad_norm': 4.109011650085449, 'learning_rate': 1.335559265442404e-05, 'epoch': 2.199499165275459}
2025-07-21 13:04:21,981 - __main__ - INFO - Step 26400: {'loss': 0.1842, 'grad_norm': 3.5435240268707275, 'learning_rate': 1.3286032276015581e-05, 'epoch': 2.2036727879799667}
2025-07-21 13:04:30,290 - __main__ - INFO - Step 26450: {'loss': 0.1678, 'grad_norm': 2.9129397869110107, 'learning_rate': 1.3216471897607125e-05, 'epoch': 2.207846410684474}
2025-07-21 13:04:38,609 - __main__ - INFO - Step 26500: {'loss': 0.173, 'grad_norm': 4.091493606567383, 'learning_rate': 1.3146911519198665e-05, 'epoch': 2.2120200333889817}
2025-07-21 13:04:44,477 - __main__ - INFO - Step 26550: {'loss': 0.1609, 'grad_norm': 4.565720558166504, 'learning_rate': 1.3077351140790205e-05, 'epoch': 2.216193656093489}
2025-07-21 13:04:52,692 - __main__ - INFO - Step 26600: {'loss': 0.1575, 'grad_norm': 1.8524819612503052, 'learning_rate': 1.3007790762381747e-05, 'epoch': 2.2203672787979967}
2025-07-21 13:05:01,045 - __main__ - INFO - Step 26650: {'loss': 0.1627, 'grad_norm': 2.740274429321289, 'learning_rate': 1.293823038397329e-05, 'epoch': 2.224540901502504}
2025-07-21 13:05:09,370 - __main__ - INFO - Step 26700: {'loss': 0.1566, 'grad_norm': 2.512796640396118, 'learning_rate': 1.2868670005564831e-05, 'epoch': 2.2287145242070117}
2025-07-21 13:05:15,379 - __main__ - INFO - Step 26750: {'loss': 0.1666, 'grad_norm': 2.898127317428589, 'learning_rate': 1.2799109627156373e-05, 'epoch': 2.2328881469115194}
2025-07-21 13:05:23,637 - __main__ - INFO - Step 26800: {'loss': 0.1642, 'grad_norm': 3.627192735671997, 'learning_rate': 1.2729549248747913e-05, 'epoch': 2.2370617696160267}
2025-07-21 13:05:31,991 - __main__ - INFO - Step 26850: {'loss': 0.163, 'grad_norm': 3.61283802986145, 'learning_rate': 1.2659988870339456e-05, 'epoch': 2.2412353923205344}
2025-07-21 13:05:40,406 - __main__ - INFO - Step 26900: {'loss': 0.1669, 'grad_norm': 2.3729465007781982, 'learning_rate': 1.2590428491930997e-05, 'epoch': 2.2454090150250416}
2025-07-21 13:05:46,335 - __main__ - INFO - Step 26950: {'loss': 0.1615, 'grad_norm': 3.6079227924346924, 'learning_rate': 1.2520868113522539e-05, 'epoch': 2.2495826377295494}
2025-07-21 13:05:54,635 - __main__ - INFO - Step 27000: {'loss': 0.1717, 'grad_norm': 2.7048985958099365, 'learning_rate': 1.245130773511408e-05, 'epoch': 2.2537562604340566}
2025-07-21 13:06:03,021 - __main__ - INFO - Step 27050: {'loss': 0.1575, 'grad_norm': 3.902310609817505, 'learning_rate': 1.238174735670562e-05, 'epoch': 2.2579298831385644}
2025-07-21 13:06:11,259 - __main__ - INFO - Step 27100: {'loss': 0.1592, 'grad_norm': 4.498390197753906, 'learning_rate': 1.2312186978297162e-05, 'epoch': 2.2621035058430716}
2025-07-21 13:06:17,184 - __main__ - INFO - Step 27150: {'loss': 0.1776, 'grad_norm': 1.5015380382537842, 'learning_rate': 1.2242626599888704e-05, 'epoch': 2.2662771285475793}
2025-07-21 13:06:25,499 - __main__ - INFO - Step 27200: {'loss': 0.1466, 'grad_norm': 4.3279829025268555, 'learning_rate': 1.2173066221480245e-05, 'epoch': 2.2704507512520866}
2025-07-21 13:06:33,894 - __main__ - INFO - Step 27250: {'loss': 0.1646, 'grad_norm': 2.105088233947754, 'learning_rate': 1.2103505843071786e-05, 'epoch': 2.2746243739565943}
2025-07-21 13:06:42,149 - __main__ - INFO - Step 27300: {'loss': 0.1577, 'grad_norm': 3.2124171257019043, 'learning_rate': 1.2033945464663328e-05, 'epoch': 2.278797996661102}
2025-07-21 13:06:47,983 - __main__ - INFO - Step 27350: {'loss': 0.1581, 'grad_norm': 1.480111002922058, 'learning_rate': 1.196438508625487e-05, 'epoch': 2.2829716193656093}
2025-07-21 13:06:56,212 - __main__ - INFO - Step 27400: {'loss': 0.1718, 'grad_norm': 2.9918031692504883, 'learning_rate': 1.189482470784641e-05, 'epoch': 2.287145242070117}
2025-07-21 13:07:04,510 - __main__ - INFO - Step 27450: {'loss': 0.1735, 'grad_norm': 1.8506203889846802, 'learning_rate': 1.1825264329437954e-05, 'epoch': 2.2913188647746243}
2025-07-21 13:07:10,482 - __main__ - INFO - Step 27500: {'loss': 0.1706, 'grad_norm': 2.5858852863311768, 'learning_rate': 1.1755703951029494e-05, 'epoch': 2.295492487479132}
2025-07-21 13:07:18,733 - __main__ - INFO - Step 27550: {'loss': 0.1651, 'grad_norm': 3.9820311069488525, 'learning_rate': 1.1686143572621036e-05, 'epoch': 2.2996661101836393}
2025-07-21 13:07:27,034 - __main__ - INFO - Step 27600: {'loss': 0.1674, 'grad_norm': 3.5104455947875977, 'learning_rate': 1.1616583194212576e-05, 'epoch': 2.303839732888147}
2025-07-21 13:07:35,416 - __main__ - INFO - Step 27650: {'loss': 0.1761, 'grad_norm': 3.4803709983825684, 'learning_rate': 1.154702281580412e-05, 'epoch': 2.3080133555926543}
2025-07-21 13:07:41,212 - __main__ - INFO - Step 27700: {'loss': 0.1712, 'grad_norm': 3.888885974884033, 'learning_rate': 1.147746243739566e-05, 'epoch': 2.312186978297162}
2025-07-21 13:07:49,432 - __main__ - INFO - Step 27750: {'loss': 0.163, 'grad_norm': 2.2290937900543213, 'learning_rate': 1.1407902058987202e-05, 'epoch': 2.3163606010016693}
2025-07-21 13:07:57,742 - __main__ - INFO - Step 27800: {'loss': 0.1649, 'grad_norm': 2.6552131175994873, 'learning_rate': 1.1338341680578744e-05, 'epoch': 2.320534223706177}
2025-07-21 13:08:06,066 - __main__ - INFO - Step 27850: {'loss': 0.1629, 'grad_norm': 4.11804723739624, 'learning_rate': 1.1268781302170284e-05, 'epoch': 2.3247078464106843}
2025-07-21 13:08:11,918 - __main__ - INFO - Step 27900: {'loss': 0.1594, 'grad_norm': 3.100285530090332, 'learning_rate': 1.1199220923761826e-05, 'epoch': 2.328881469115192}
2025-07-21 13:08:20,128 - __main__ - INFO - Step 27950: {'loss': 0.1749, 'grad_norm': 3.4028661251068115, 'learning_rate': 1.1129660545353366e-05, 'epoch': 2.3330550918196993}
2025-07-21 13:08:28,507 - __main__ - INFO - Step 28000: {'loss': 0.1466, 'grad_norm': 3.0846166610717773, 'learning_rate': 1.106010016694491e-05, 'epoch': 2.337228714524207}
2025-07-21 13:08:36,840 - __main__ - INFO - Step 28050: {'loss': 0.1723, 'grad_norm': 6.91595983505249, 'learning_rate': 1.099053978853645e-05, 'epoch': 2.3414023372287147}
2025-07-21 13:08:42,645 - __main__ - INFO - Step 28100: {'loss': 0.1686, 'grad_norm': 3.681314468383789, 'learning_rate': 1.0920979410127992e-05, 'epoch': 2.345575959933222}
2025-07-21 13:08:50,843 - __main__ - INFO - Step 28150: {'loss': 0.182, 'grad_norm': 2.189621686935425, 'learning_rate': 1.0851419031719533e-05, 'epoch': 2.3497495826377297}
2025-07-21 13:08:59,170 - __main__ - INFO - Step 28200: {'loss': 0.1611, 'grad_norm': 4.157842636108398, 'learning_rate': 1.0781858653311075e-05, 'epoch': 2.353923205342237}
2025-07-21 13:09:07,532 - __main__ - INFO - Step 28250: {'loss': 0.1769, 'grad_norm': 6.455710411071777, 'learning_rate': 1.0712298274902615e-05, 'epoch': 2.3580968280467447}
2025-07-21 13:09:13,473 - __main__ - INFO - Step 28300: {'loss': 0.1596, 'grad_norm': 4.12042236328125, 'learning_rate': 1.0642737896494157e-05, 'epoch': 2.362270450751252}
2025-07-21 13:09:21,739 - __main__ - INFO - Step 28350: {'loss': 0.1607, 'grad_norm': 2.370661735534668, 'learning_rate': 1.05731775180857e-05, 'epoch': 2.3664440734557597}
2025-07-21 13:09:30,139 - __main__ - INFO - Step 28400: {'loss': 0.1691, 'grad_norm': 2.0698001384735107, 'learning_rate': 1.0503617139677241e-05, 'epoch': 2.370617696160267}
2025-07-21 13:09:38,380 - __main__ - INFO - Step 28450: {'loss': 0.1696, 'grad_norm': 3.477550745010376, 'learning_rate': 1.0434056761268781e-05, 'epoch': 2.3747913188647747}
2025-07-21 13:09:44,280 - __main__ - INFO - Step 28500: {'loss': 0.1648, 'grad_norm': 3.043034315109253, 'learning_rate': 1.0364496382860323e-05, 'epoch': 2.378964941569282}
2025-07-21 13:09:52,520 - __main__ - INFO - Step 28550: {'loss': 0.1731, 'grad_norm': 3.905597448348999, 'learning_rate': 1.0294936004451865e-05, 'epoch': 2.3831385642737897}
2025-07-21 13:10:00,835 - __main__ - INFO - Step 28600: {'loss': 0.1604, 'grad_norm': 3.191641330718994, 'learning_rate': 1.0225375626043405e-05, 'epoch': 2.3873121869782974}
2025-07-21 13:10:09,152 - __main__ - INFO - Step 28650: {'loss': 0.1713, 'grad_norm': 5.193282604217529, 'learning_rate': 1.0155815247634947e-05, 'epoch': 2.3914858096828047}
2025-07-21 13:10:15,124 - __main__ - INFO - Step 28700: {'loss': 0.1778, 'grad_norm': 3.708630323410034, 'learning_rate': 1.0086254869226489e-05, 'epoch': 2.395659432387312}
2025-07-21 13:10:23,446 - __main__ - INFO - Step 28750: {'loss': 0.1787, 'grad_norm': 3.9092319011688232, 'learning_rate': 1.001669449081803e-05, 'epoch': 2.3998330550918197}
2025-07-21 13:10:31,781 - __main__ - INFO - Step 28800: {'loss': 0.1547, 'grad_norm': 3.593858242034912, 'learning_rate': 9.948525319977741e-06, 'epoch': 2.4040066777963274}
2025-07-21 13:10:40,088 - __main__ - INFO - Step 28850: {'loss': 0.1563, 'grad_norm': 3.410766839981079, 'learning_rate': 9.878964941569283e-06, 'epoch': 2.4081803005008346}
2025-07-21 13:10:46,081 - __main__ - INFO - Step 28900: {'loss': 0.1569, 'grad_norm': 2.4389679431915283, 'learning_rate': 9.809404563160825e-06, 'epoch': 2.4123539232053424}
2025-07-21 13:10:54,400 - __main__ - INFO - Step 28950: {'loss': 0.1628, 'grad_norm': 3.488773822784424, 'learning_rate': 9.739844184752365e-06, 'epoch': 2.4165275459098496}
2025-07-21 13:11:02,755 - __main__ - INFO - Step 29000: {'loss': 0.1729, 'grad_norm': 4.4202141761779785, 'learning_rate': 9.670283806343907e-06, 'epoch': 2.4207011686143574}
2025-07-21 13:11:11,208 - __main__ - INFO - Step 29050: {'loss': 0.1572, 'grad_norm': 3.6115715503692627, 'learning_rate': 9.600723427935449e-06, 'epoch': 2.4248747913188646}
2025-07-21 13:11:17,139 - __main__ - INFO - Step 29100: {'loss': 0.1626, 'grad_norm': 3.4453766345977783, 'learning_rate': 9.531163049526989e-06, 'epoch': 2.4290484140233723}
2025-07-21 13:11:25,450 - __main__ - INFO - Step 29150: {'loss': 0.1685, 'grad_norm': 2.892932176589966, 'learning_rate': 9.461602671118532e-06, 'epoch': 2.4332220367278796}
2025-07-21 13:11:33,717 - __main__ - INFO - Step 29200: {'loss': 0.1505, 'grad_norm': 2.933183193206787, 'learning_rate': 9.392042292710073e-06, 'epoch': 2.4373956594323873}
2025-07-21 13:11:39,547 - __main__ - INFO - Step 29250: {'loss': 0.1557, 'grad_norm': 2.4729769229888916, 'learning_rate': 9.322481914301614e-06, 'epoch': 2.4415692821368946}
2025-07-21 13:11:47,739 - __main__ - INFO - Step 29300: {'loss': 0.164, 'grad_norm': 4.278615474700928, 'learning_rate': 9.252921535893155e-06, 'epoch': 2.4457429048414023}
2025-07-21 13:11:55,989 - __main__ - INFO - Step 29350: {'loss': 0.164, 'grad_norm': 3.642725944519043, 'learning_rate': 9.183361157484698e-06, 'epoch': 2.44991652754591}
2025-07-21 13:12:04,314 - __main__ - INFO - Step 29400: {'loss': 0.1785, 'grad_norm': 3.6034672260284424, 'learning_rate': 9.113800779076238e-06, 'epoch': 2.4540901502504173}
2025-07-21 13:12:10,395 - __main__ - INFO - Step 29450: {'loss': 0.1636, 'grad_norm': 2.8859376907348633, 'learning_rate': 9.04424040066778e-06, 'epoch': 2.458263772954925}
2025-07-21 13:12:18,703 - __main__ - INFO - Step 29500: {'loss': 0.1676, 'grad_norm': 4.72629976272583, 'learning_rate': 8.974680022259322e-06, 'epoch': 2.4624373956594323}
2025-07-21 13:12:27,040 - __main__ - INFO - Step 29550: {'loss': 0.1718, 'grad_norm': 2.0875210762023926, 'learning_rate': 8.905119643850864e-06, 'epoch': 2.46661101836394}
2025-07-21 13:12:35,304 - __main__ - INFO - Step 29600: {'loss': 0.1665, 'grad_norm': 4.620769023895264, 'learning_rate': 8.835559265442404e-06, 'epoch': 2.4707846410684473}
2025-07-21 13:12:41,270 - __main__ - INFO - Step 29650: {'loss': 0.1598, 'grad_norm': 3.642477512359619, 'learning_rate': 8.765998887033946e-06, 'epoch': 2.474958263772955}
2025-07-21 13:12:49,614 - __main__ - INFO - Step 29700: {'loss': 0.1712, 'grad_norm': 4.678242206573486, 'learning_rate': 8.696438508625488e-06, 'epoch': 2.4791318864774623}
2025-07-21 13:12:58,071 - __main__ - INFO - Step 29750: {'loss': 0.1647, 'grad_norm': 4.009243488311768, 'learning_rate': 8.626878130217028e-06, 'epoch': 2.48330550918197}
2025-07-21 13:13:06,524 - __main__ - INFO - Step 29800: {'loss': 0.1569, 'grad_norm': 3.463238477706909, 'learning_rate': 8.55731775180857e-06, 'epoch': 2.4874791318864773}
2025-07-21 13:13:12,636 - __main__ - INFO - Step 29850: {'loss': 0.1694, 'grad_norm': 3.464846611022949, 'learning_rate': 8.487757373400112e-06, 'epoch': 2.491652754590985}
2025-07-21 13:13:21,029 - __main__ - INFO - Step 29900: {'loss': 0.189, 'grad_norm': 3.0993645191192627, 'learning_rate': 8.418196994991654e-06, 'epoch': 2.4958263772954927}
2025-07-21 13:13:29,500 - __main__ - INFO - Step 29950: {'loss': 0.1598, 'grad_norm': 2.9347379207611084, 'learning_rate': 8.348636616583194e-06, 'epoch': 2.5}
2025-07-21 13:13:37,873 - __main__ - INFO - Step 30000: {'loss': 0.1697, 'grad_norm': 3.7152910232543945, 'learning_rate': 8.279076238174736e-06, 'epoch': 2.5041736227045073}
2025-07-21 13:13:43,766 - __main__ - INFO - Step 30050: {'loss': 0.177, 'grad_norm': 4.705827236175537, 'learning_rate': 8.209515859766278e-06, 'epoch': 2.508347245409015}
2025-07-21 13:13:52,007 - __main__ - INFO - Step 30100: {'loss': 0.169, 'grad_norm': 4.222662925720215, 'learning_rate': 8.13995548135782e-06, 'epoch': 2.5125208681135227}
2025-07-21 13:14:00,331 - __main__ - INFO - Step 30150: {'loss': 0.1623, 'grad_norm': 2.967715263366699, 'learning_rate': 8.07039510294936e-06, 'epoch': 2.51669449081803}
2025-07-21 13:14:08,613 - __main__ - INFO - Step 30200: {'loss': 0.1625, 'grad_norm': 4.130316734313965, 'learning_rate': 8.000834724540902e-06, 'epoch': 2.5208681135225377}
2025-07-21 13:14:14,579 - __main__ - INFO - Step 30250: {'loss': 0.1692, 'grad_norm': 4.654603004455566, 'learning_rate': 7.931274346132443e-06, 'epoch': 2.525041736227045}
2025-07-21 13:14:22,959 - __main__ - INFO - Step 30300: {'loss': 0.1653, 'grad_norm': 3.958834648132324, 'learning_rate': 7.861713967723985e-06, 'epoch': 2.5292153589315527}
2025-07-21 13:14:31,368 - __main__ - INFO - Step 30350: {'loss': 0.1616, 'grad_norm': 2.8477296829223633, 'learning_rate': 7.792153589315525e-06, 'epoch': 2.53338898163606}
2025-07-21 13:14:39,595 - __main__ - INFO - Step 30400: {'loss': 0.1627, 'grad_norm': 4.605696678161621, 'learning_rate': 7.722593210907069e-06, 'epoch': 2.5375626043405677}
2025-07-21 13:14:45,513 - __main__ - INFO - Step 30450: {'loss': 0.1711, 'grad_norm': 4.388598442077637, 'learning_rate': 7.65303283249861e-06, 'epoch': 2.5417362270450754}
2025-07-21 13:14:53,756 - __main__ - INFO - Step 30500: {'loss': 0.171, 'grad_norm': 3.497828722000122, 'learning_rate': 7.58347245409015e-06, 'epoch': 2.5459098497495827}
2025-07-21 13:15:02,095 - __main__ - INFO - Step 30550: {'loss': 0.1554, 'grad_norm': 3.705153703689575, 'learning_rate': 7.513912075681692e-06, 'epoch': 2.55008347245409}
2025-07-21 13:15:10,396 - __main__ - INFO - Step 30600: {'loss': 0.1612, 'grad_norm': 5.2796196937561035, 'learning_rate': 7.444351697273233e-06, 'epoch': 2.5542570951585977}
2025-07-21 13:15:16,333 - __main__ - INFO - Step 30650: {'loss': 0.159, 'grad_norm': 5.983048915863037, 'learning_rate': 7.374791318864775e-06, 'epoch': 2.5584307178631054}
2025-07-21 13:15:24,632 - __main__ - INFO - Step 30700: {'loss': 0.1587, 'grad_norm': 2.835280418395996, 'learning_rate': 7.305230940456316e-06, 'epoch': 2.5626043405676127}
2025-07-21 13:15:33,049 - __main__ - INFO - Step 30750: {'loss': 0.1582, 'grad_norm': 2.6411709785461426, 'learning_rate': 7.235670562047858e-06, 'epoch': 2.56677796327212}
2025-07-21 13:15:38,980 - __main__ - INFO - Step 30800: {'loss': 0.1613, 'grad_norm': 3.8233587741851807, 'learning_rate': 7.167501391207569e-06, 'epoch': 2.5709515859766277}
2025-07-21 13:15:47,271 - __main__ - INFO - Step 30850: {'loss': 0.1728, 'grad_norm': 4.965890407562256, 'learning_rate': 7.09794101279911e-06, 'epoch': 2.5751252086811354}
2025-07-21 13:15:55,603 - __main__ - INFO - Step 30900: {'loss': 0.1642, 'grad_norm': 5.4230194091796875, 'learning_rate': 7.028380634390651e-06, 'epoch': 2.5792988313856426}
2025-07-21 13:16:03,923 - __main__ - INFO - Step 30950: {'loss': 0.1579, 'grad_norm': 3.375666856765747, 'learning_rate': 6.958820255982193e-06, 'epoch': 2.5834724540901504}
2025-07-21 13:16:09,921 - __main__ - INFO - Step 31000: {'loss': 0.1483, 'grad_norm': 4.047967433929443, 'learning_rate': 6.889259877573734e-06, 'epoch': 2.5876460767946576}
2025-07-21 13:16:18,169 - __main__ - INFO - Step 31050: {'loss': 0.1674, 'grad_norm': 4.66559362411499, 'learning_rate': 6.819699499165276e-06, 'epoch': 2.5918196994991654}
2025-07-21 13:16:26,489 - __main__ - INFO - Step 31100: {'loss': 0.1599, 'grad_norm': 3.670125961303711, 'learning_rate': 6.750139120756817e-06, 'epoch': 2.5959933222036726}
2025-07-21 13:16:34,942 - __main__ - INFO - Step 31150: {'loss': 0.1572, 'grad_norm': 3.4155263900756836, 'learning_rate': 6.680578742348359e-06, 'epoch': 2.6001669449081803}
2025-07-21 13:16:40,852 - __main__ - INFO - Step 31200: {'loss': 0.1599, 'grad_norm': 6.054743766784668, 'learning_rate': 6.6110183639399e-06, 'epoch': 2.604340567612688}
2025-07-21 13:16:49,081 - __main__ - INFO - Step 31250: {'loss': 0.1579, 'grad_norm': 4.275594234466553, 'learning_rate': 6.541457985531442e-06, 'epoch': 2.6085141903171953}
2025-07-21 13:16:57,422 - __main__ - INFO - Step 31300: {'loss': 0.1699, 'grad_norm': 3.02236270904541, 'learning_rate': 6.4718976071229825e-06, 'epoch': 2.6126878130217026}
2025-07-21 13:17:05,742 - __main__ - INFO - Step 31350: {'loss': 0.1785, 'grad_norm': 2.1723225116729736, 'learning_rate': 6.402337228714525e-06, 'epoch': 2.6168614357262103}
2025-07-21 13:17:11,470 - __main__ - INFO - Step 31400: {'loss': 0.1656, 'grad_norm': 5.882161617279053, 'learning_rate': 6.3327768503060655e-06, 'epoch': 2.621035058430718}
2025-07-21 13:17:19,745 - __main__ - INFO - Step 31450: {'loss': 0.1601, 'grad_norm': 3.1544628143310547, 'learning_rate': 6.263216471897608e-06, 'epoch': 2.6252086811352253}
2025-07-21 13:17:28,145 - __main__ - INFO - Step 31500: {'loss': 0.1613, 'grad_norm': 3.803032636642456, 'learning_rate': 6.193656093489149e-06, 'epoch': 2.629382303839733}
2025-07-21 13:17:36,513 - __main__ - INFO - Step 31550: {'loss': 0.1657, 'grad_norm': 2.4137473106384277, 'learning_rate': 6.12409571508069e-06, 'epoch': 2.6335559265442403}
2025-07-21 13:17:42,472 - __main__ - INFO - Step 31600: {'loss': 0.1677, 'grad_norm': 3.7149009704589844, 'learning_rate': 6.054535336672232e-06, 'epoch': 2.637729549248748}
2025-07-21 13:17:50,686 - __main__ - INFO - Step 31650: {'loss': 0.1723, 'grad_norm': 3.4723193645477295, 'learning_rate': 5.984974958263773e-06, 'epoch': 2.6419031719532553}
2025-07-21 13:17:59,002 - __main__ - INFO - Step 31700: {'loss': 0.1617, 'grad_norm': 1.9969069957733154, 'learning_rate': 5.915414579855315e-06, 'epoch': 2.646076794657763}
2025-07-21 13:18:07,292 - __main__ - INFO - Step 31750: {'loss': 0.1686, 'grad_norm': 1.21351957321167, 'learning_rate': 5.845854201446856e-06, 'epoch': 2.6502504173622703}
2025-07-21 13:18:13,235 - __main__ - INFO - Step 31800: {'loss': 0.1689, 'grad_norm': 4.697266101837158, 'learning_rate': 5.776293823038398e-06, 'epoch': 2.654424040066778}
2025-07-21 13:18:21,500 - __main__ - INFO - Step 31850: {'loss': 0.1579, 'grad_norm': 4.478855133056641, 'learning_rate': 5.706733444629939e-06, 'epoch': 2.6585976627712853}
2025-07-21 13:18:29,860 - __main__ - INFO - Step 31900: {'loss': 0.1579, 'grad_norm': 5.066263675689697, 'learning_rate': 5.637173066221481e-06, 'epoch': 2.662771285475793}
2025-07-21 13:18:38,108 - __main__ - INFO - Step 31950: {'loss': 0.1636, 'grad_norm': 3.7650113105773926, 'learning_rate': 5.567612687813022e-06, 'epoch': 2.6669449081803007}
2025-07-21 13:18:43,954 - __main__ - INFO - Step 32000: {'loss': 0.1636, 'grad_norm': 3.2461979389190674, 'learning_rate': 5.498052309404563e-06, 'epoch': 2.671118530884808}
2025-07-21 13:18:52,332 - __main__ - INFO - Step 32050: {'loss': 0.1445, 'grad_norm': 5.149737358093262, 'learning_rate': 5.428491930996105e-06, 'epoch': 2.6752921535893153}
2025-07-21 13:19:00,740 - __main__ - INFO - Step 32100: {'loss': 0.1615, 'grad_norm': 3.463792562484741, 'learning_rate': 5.358931552587646e-06, 'epoch': 2.679465776293823}
2025-07-21 13:19:09,095 - __main__ - INFO - Step 32150: {'loss': 0.1606, 'grad_norm': 1.902703046798706, 'learning_rate': 5.289371174179188e-06, 'epoch': 2.6836393989983307}
2025-07-21 13:19:15,013 - __main__ - INFO - Step 32200: {'loss': 0.1574, 'grad_norm': 2.447430372238159, 'learning_rate': 5.2198107957707295e-06, 'epoch': 2.687813021702838}
2025-07-21 13:19:23,282 - __main__ - INFO - Step 32250: {'loss': 0.1695, 'grad_norm': 4.341437339782715, 'learning_rate': 5.1502504173622706e-06, 'epoch': 2.6919866444073457}
2025-07-21 13:19:31,751 - __main__ - INFO - Step 32300: {'loss': 0.1629, 'grad_norm': 2.8315179347991943, 'learning_rate': 5.0806900389538124e-06, 'epoch': 2.696160267111853}
2025-07-21 13:19:40,006 - __main__ - INFO - Step 32350: {'loss': 0.1561, 'grad_norm': 2.642791986465454, 'learning_rate': 5.0111296605453535e-06, 'epoch': 2.7003338898163607}
2025-07-21 13:19:45,945 - __main__ - INFO - Step 32400: {'loss': 0.1766, 'grad_norm': 3.277714490890503, 'learning_rate': 4.941569282136895e-06, 'epoch': 2.704507512520868}
2025-07-21 13:19:54,236 - __main__ - INFO - Step 32450: {'loss': 0.1776, 'grad_norm': 5.114622592926025, 'learning_rate': 4.872008903728436e-06, 'epoch': 2.7086811352253757}
2025-07-21 13:20:02,563 - __main__ - INFO - Step 32500: {'loss': 0.172, 'grad_norm': 5.302189826965332, 'learning_rate': 4.802448525319978e-06, 'epoch': 2.7128547579298834}
2025-07-21 13:20:10,819 - __main__ - INFO - Step 32550: {'loss': 0.1622, 'grad_norm': 2.475268602371216, 'learning_rate': 4.732888146911519e-06, 'epoch': 2.7170283806343907}
2025-07-21 13:20:16,639 - __main__ - INFO - Step 32600: {'loss': 0.159, 'grad_norm': 2.595597505569458, 'learning_rate': 4.663327768503061e-06, 'epoch': 2.721202003338898}
2025-07-21 13:20:25,063 - __main__ - INFO - Step 32650: {'loss': 0.1588, 'grad_norm': 2.901278495788574, 'learning_rate': 4.593767390094603e-06, 'epoch': 2.7253756260434057}
2025-07-21 13:20:33,546 - __main__ - INFO - Step 32700: {'loss': 0.1683, 'grad_norm': 3.125221014022827, 'learning_rate': 4.524207011686143e-06, 'epoch': 2.7295492487479134}
2025-07-21 13:20:39,582 - __main__ - INFO - Step 32750: {'loss': 0.1665, 'grad_norm': 5.308164596557617, 'learning_rate': 4.454646633277685e-06, 'epoch': 2.7337228714524207}
2025-07-21 13:20:47,798 - __main__ - INFO - Step 32800: {'loss': 0.1685, 'grad_norm': 3.2725727558135986, 'learning_rate': 4.385086254869226e-06, 'epoch': 2.7378964941569284}
2025-07-21 13:20:56,089 - __main__ - INFO - Step 32850: {'loss': 0.1785, 'grad_norm': 4.411677837371826, 'learning_rate': 4.315525876460768e-06, 'epoch': 2.7420701168614356}
2025-07-21 13:21:04,529 - __main__ - INFO - Step 32900: {'loss': 0.176, 'grad_norm': 5.207944869995117, 'learning_rate': 4.24596549805231e-06, 'epoch': 2.7462437395659434}
2025-07-21 13:21:10,463 - __main__ - INFO - Step 32950: {'loss': 0.1624, 'grad_norm': 2.769848585128784, 'learning_rate': 4.177796327212021e-06, 'epoch': 2.7504173622704506}
2025-07-21 13:21:18,776 - __main__ - INFO - Step 33000: {'loss': 0.1621, 'grad_norm': 5.193027019500732, 'learning_rate': 4.108235948803562e-06, 'epoch': 2.7545909849749584}
2025-07-21 13:21:27,197 - __main__ - INFO - Step 33050: {'loss': 0.1625, 'grad_norm': 4.244845390319824, 'learning_rate': 4.038675570395104e-06, 'epoch': 2.7587646076794656}
2025-07-21 13:21:35,553 - __main__ - INFO - Step 33100: {'loss': 0.1734, 'grad_norm': 3.69846510887146, 'learning_rate': 3.969115191986644e-06, 'epoch': 2.7629382303839733}
2025-07-21 13:21:41,420 - __main__ - INFO - Step 33150: {'loss': 0.1603, 'grad_norm': 4.070649147033691, 'learning_rate': 3.899554813578186e-06, 'epoch': 2.7671118530884806}
2025-07-21 13:21:49,626 - __main__ - INFO - Step 33200: {'loss': 0.1738, 'grad_norm': 4.539525508880615, 'learning_rate': 3.829994435169728e-06, 'epoch': 2.7712854757929883}
2025-07-21 13:21:57,897 - __main__ - INFO - Step 33250: {'loss': 0.1482, 'grad_norm': 4.1135406494140625, 'learning_rate': 3.7604340567612686e-06, 'epoch': 2.775459098497496}
2025-07-21 13:22:06,223 - __main__ - INFO - Step 33300: {'loss': 0.16, 'grad_norm': 4.815640449523926, 'learning_rate': 3.69087367835281e-06, 'epoch': 2.7796327212020033}
2025-07-21 13:22:12,193 - __main__ - INFO - Step 33350: {'loss': 0.1722, 'grad_norm': 4.435549259185791, 'learning_rate': 3.621313299944352e-06, 'epoch': 2.7838063439065106}
2025-07-21 13:22:20,395 - __main__ - INFO - Step 33400: {'loss': 0.173, 'grad_norm': 2.5306289196014404, 'learning_rate': 3.5517529215358934e-06, 'epoch': 2.7879799666110183}
2025-07-21 13:22:28,828 - __main__ - INFO - Step 33450: {'loss': 0.1596, 'grad_norm': 2.8270323276519775, 'learning_rate': 3.482192543127435e-06, 'epoch': 2.792153589315526}
2025-07-21 13:22:37,083 - __main__ - INFO - Step 33500: {'loss': 0.1513, 'grad_norm': 4.455460071563721, 'learning_rate': 3.4126321647189763e-06, 'epoch': 2.7963272120200333}
2025-07-21 13:22:42,932 - __main__ - INFO - Step 33550: {'loss': 0.161, 'grad_norm': 3.503612995147705, 'learning_rate': 3.3430717863105178e-06, 'epoch': 2.800500834724541}
2025-07-21 13:22:51,278 - __main__ - INFO - Step 33600: {'loss': 0.1789, 'grad_norm': 3.6279678344726562, 'learning_rate': 3.2735114079020592e-06, 'epoch': 2.8046744574290483}
2025-07-21 13:22:59,708 - __main__ - INFO - Step 33650: {'loss': 0.157, 'grad_norm': 4.994856834411621, 'learning_rate': 3.2039510294936007e-06, 'epoch': 2.808848080133556}
2025-07-21 13:23:08,014 - __main__ - INFO - Step 33700: {'loss': 0.1615, 'grad_norm': 3.9517428874969482, 'learning_rate': 3.134390651085142e-06, 'epoch': 2.8130217028380633}
2025-07-21 13:23:13,945 - __main__ - INFO - Step 33750: {'loss': 0.1624, 'grad_norm': 2.5604004859924316, 'learning_rate': 3.0648302726766836e-06, 'epoch': 2.817195325542571}
2025-07-21 13:23:22,298 - __main__ - INFO - Step 33800: {'loss': 0.131, 'grad_norm': 3.7122318744659424, 'learning_rate': 2.995269894268225e-06, 'epoch': 2.8213689482470787}
2025-07-21 13:23:30,691 - __main__ - INFO - Step 33850: {'loss': 0.1506, 'grad_norm': 8.094929695129395, 'learning_rate': 2.9257095158597665e-06, 'epoch': 2.825542570951586}
2025-07-21 13:23:38,904 - __main__ - INFO - Step 33900: {'loss': 0.1714, 'grad_norm': 3.152853012084961, 'learning_rate': 2.856149137451308e-06, 'epoch': 2.8297161936560933}
2025-07-21 13:23:44,774 - __main__ - INFO - Step 33950: {'loss': 0.1639, 'grad_norm': 4.554925441741943, 'learning_rate': 2.7865887590428494e-06, 'epoch': 2.833889816360601}
2025-07-21 13:23:53,042 - __main__ - INFO - Step 34000: {'loss': 0.1512, 'grad_norm': 4.021955966949463, 'learning_rate': 2.717028380634391e-06, 'epoch': 2.8380634390651087}
2025-07-21 13:24:01,369 - __main__ - INFO - Step 34050: {'loss': 0.1575, 'grad_norm': 4.3651933670043945, 'learning_rate': 2.6474680022259323e-06, 'epoch': 2.842237061769616}
2025-07-21 13:24:09,607 - __main__ - INFO - Step 34100: {'loss': 0.1828, 'grad_norm': 3.564192056655884, 'learning_rate': 2.5779076238174738e-06, 'epoch': 2.8464106844741233}
2025-07-21 13:24:15,510 - __main__ - INFO - Step 34150: {'loss': 0.1652, 'grad_norm': 2.8510642051696777, 'learning_rate': 2.5083472454090152e-06, 'epoch': 2.850584307178631}
2025-07-21 13:24:23,831 - __main__ - INFO - Step 34200: {'loss': 0.1528, 'grad_norm': 3.761075258255005, 'learning_rate': 2.4387868670005567e-06, 'epoch': 2.8547579298831387}
2025-07-21 13:24:32,181 - __main__ - INFO - Step 34250: {'loss': 0.1729, 'grad_norm': 2.6983284950256348, 'learning_rate': 2.369226488592098e-06, 'epoch': 2.858931552587646}
2025-07-21 13:24:40,491 - __main__ - INFO - Step 34300: {'loss': 0.1653, 'grad_norm': 3.925821542739868, 'learning_rate': 2.2996661101836396e-06, 'epoch': 2.8631051752921537}
2025-07-21 13:24:46,388 - __main__ - INFO - Step 34350: {'loss': 0.1567, 'grad_norm': 3.895232915878296, 'learning_rate': 2.230105731775181e-06, 'epoch': 2.867278797996661}
2025-07-21 13:24:54,652 - __main__ - INFO - Step 34400: {'loss': 0.1657, 'grad_norm': 4.127828121185303, 'learning_rate': 2.1605453533667225e-06, 'epoch': 2.8714524207011687}
2025-07-21 13:25:03,041 - __main__ - INFO - Step 34450: {'loss': 0.1681, 'grad_norm': 3.4301917552948, 'learning_rate': 2.090984974958264e-06, 'epoch': 2.875626043405676}
2025-07-21 13:25:11,349 - __main__ - INFO - Step 34500: {'loss': 0.1524, 'grad_norm': 2.5749080181121826, 'learning_rate': 2.0214245965498054e-06, 'epoch': 2.8797996661101837}
2025-07-21 13:25:17,415 - __main__ - INFO - Step 34550: {'loss': 0.1621, 'grad_norm': 2.4690749645233154, 'learning_rate': 1.951864218141347e-06, 'epoch': 2.8839732888146914}
2025-07-21 13:25:25,853 - __main__ - INFO - Step 34600: {'loss': 0.1642, 'grad_norm': 4.9666314125061035, 'learning_rate': 1.8823038397328883e-06, 'epoch': 2.8881469115191987}
2025-07-21 13:25:34,273 - __main__ - INFO - Step 34650: {'loss': 0.1609, 'grad_norm': 2.6912841796875, 'learning_rate': 1.8127434613244297e-06, 'epoch': 2.892320534223706}
2025-07-21 13:25:40,008 - __main__ - INFO - Step 34700: {'loss': 0.17, 'grad_norm': 4.937735080718994, 'learning_rate': 1.7431830829159712e-06, 'epoch': 2.8964941569282137}
2025-07-21 13:25:48,202 - __main__ - INFO - Step 34750: {'loss': 0.1586, 'grad_norm': 2.748800754547119, 'learning_rate': 1.6736227045075124e-06, 'epoch': 2.9006677796327214}
2025-07-21 13:25:56,473 - __main__ - INFO - Step 34800: {'loss': 0.1618, 'grad_norm': 3.2430949211120605, 'learning_rate': 1.6040623260990539e-06, 'epoch': 2.9048414023372287}
2025-07-21 13:26:04,800 - __main__ - INFO - Step 34850: {'loss': 0.152, 'grad_norm': 2.257697343826294, 'learning_rate': 1.5345019476905953e-06, 'epoch': 2.9090150250417364}
2025-07-21 13:26:10,866 - __main__ - INFO - Step 34900: {'loss': 0.1566, 'grad_norm': 4.950591564178467, 'learning_rate': 1.464941569282137e-06, 'epoch': 2.9131886477462436}
2025-07-21 13:26:19,216 - __main__ - INFO - Step 34950: {'loss': 0.1747, 'grad_norm': 3.7409632205963135, 'learning_rate': 1.3953811908736785e-06, 'epoch': 2.9173622704507514}
2025-07-21 13:26:27,557 - __main__ - INFO - Step 35000: {'loss': 0.1679, 'grad_norm': 2.1007583141326904, 'learning_rate': 1.32582081246522e-06, 'epoch': 2.9215358931552586}
2025-07-21 13:26:35,896 - __main__ - INFO - Step 35050: {'loss': 0.1588, 'grad_norm': 3.4158689975738525, 'learning_rate': 1.2576516416249306e-06, 'epoch': 2.9257095158597664}
2025-07-21 13:26:41,755 - __main__ - INFO - Step 35100: {'loss': 0.1843, 'grad_norm': 2.5898706912994385, 'learning_rate': 1.1880912632164718e-06, 'epoch': 2.9298831385642736}
2025-07-21 13:26:49,997 - __main__ - INFO - Step 35150: {'loss': 0.1655, 'grad_norm': 2.3809778690338135, 'learning_rate': 1.1185308848080135e-06, 'epoch': 2.9340567612687813}
2025-07-21 13:26:58,376 - __main__ - INFO - Step 35200: {'loss': 0.1603, 'grad_norm': 3.889483690261841, 'learning_rate': 1.050361713967724e-06, 'epoch': 2.9382303839732886}
2025-07-21 13:27:06,622 - __main__ - INFO - Step 35250: {'loss': 0.153, 'grad_norm': 2.2323033809661865, 'learning_rate': 9.808013355592656e-07, 'epoch': 2.9424040066777963}
2025-07-21 13:27:12,525 - __main__ - INFO - Step 35300: {'loss': 0.1544, 'grad_norm': 4.72238302230835, 'learning_rate': 9.112409571508069e-07, 'epoch': 2.946577629382304}
2025-07-21 13:27:20,753 - __main__ - INFO - Step 35350: {'loss': 0.172, 'grad_norm': 2.5414011478424072, 'learning_rate': 8.416805787423483e-07, 'epoch': 2.9507512520868113}
2025-07-21 13:27:29,117 - __main__ - INFO - Step 35400: {'loss': 0.1561, 'grad_norm': 4.51931095123291, 'learning_rate': 7.721202003338899e-07, 'epoch': 2.9549248747913186}
2025-07-21 13:27:37,376 - __main__ - INFO - Step 35450: {'loss': 0.1729, 'grad_norm': 4.811465263366699, 'learning_rate': 7.025598219254314e-07, 'epoch': 2.9590984974958263}
2025-07-21 13:27:43,284 - __main__ - INFO - Step 35500: {'loss': 0.1662, 'grad_norm': 2.9255244731903076, 'learning_rate': 6.329994435169728e-07, 'epoch': 2.963272120200334}
2025-07-21 13:27:51,533 - __main__ - INFO - Step 35550: {'loss': 0.1625, 'grad_norm': 1.5648490190505981, 'learning_rate': 5.634390651085143e-07, 'epoch': 2.9674457429048413}
2025-07-21 13:27:59,909 - __main__ - INFO - Step 35600: {'loss': 0.1622, 'grad_norm': 4.932590007781982, 'learning_rate': 4.938786867000556e-07, 'epoch': 2.971619365609349}
2025-07-21 13:28:08,220 - __main__ - INFO - Step 35650: {'loss': 0.1595, 'grad_norm': 4.084844589233398, 'learning_rate': 4.2431830829159716e-07, 'epoch': 2.9757929883138563}
2025-07-21 13:28:14,000 - __main__ - INFO - Step 35700: {'loss': 0.1751, 'grad_norm': 3.9279773235321045, 'learning_rate': 3.547579298831386e-07, 'epoch': 2.979966611018364}
2025-07-21 13:28:22,235 - __main__ - INFO - Step 35750: {'loss': 0.1688, 'grad_norm': 3.608971357345581, 'learning_rate': 2.8519755147468007e-07, 'epoch': 2.9841402337228713}
2025-07-21 13:28:30,597 - __main__ - INFO - Step 35800: {'loss': 0.1705, 'grad_norm': 5.202012062072754, 'learning_rate': 2.1563717306622152e-07, 'epoch': 2.988313856427379}
2025-07-21 13:28:38,883 - __main__ - INFO - Step 35850: {'loss': 0.1553, 'grad_norm': 4.369693279266357, 'learning_rate': 1.4607679465776294e-07, 'epoch': 2.9924874791318867}
2025-07-21 13:28:44,794 - __main__ - INFO - Step 35900: {'loss': 0.1455, 'grad_norm': 2.5354416370391846, 'learning_rate': 7.651641624930441e-08, 'epoch': 2.996661101836394}
2025-07-21 13:28:51,683 - __main__ - INFO - Epoch 3.0 completed in 1844.87 seconds
2025-07-21 13:29:45,541 - __main__ - INFO - Step 35940: {'eval_loss': 0.32300156354904175, 'eval_runtime': 53.8545, 'eval_samples_per_second': 1581.856, 'eval_steps_per_second': 24.733, 'epoch': 3.0}
2025-07-21 13:29:47,388 - __main__ - INFO - Step 35940: {'train_runtime': 5916.7399, 'train_samples_per_second': 388.748, 'train_steps_per_second': 6.074, 'total_flos': 7.617266201546035e+16, 'train_loss': 0.23766242132362023, 'epoch': 3.0}
2025-07-21 13:29:47,391 - __main__ - INFO - 🎉 Training completed!
2025-07-21 13:29:47,391 - __main__ - INFO - Total training time: 5916.74 seconds (98.61 minutes)
2025-07-21 13:29:47,394 - __main__ - INFO - ==================================================
2025-07-21 13:29:47,394 - __main__ - INFO - TRAINING COMPLETED - STARTING EVALUATION
2025-07-21 13:29:47,394 - __main__ - INFO - ==================================================
2025-07-21 13:30:41,640 - __main__ - INFO - Step 35940: {'eval_loss': 0.2821662724018097, 'eval_runtime': 54.2454, 'eval_samples_per_second': 1570.455, 'eval_steps_per_second': 24.555, 'epoch': 3.0}
2025-07-21 13:30:41,640 - __main__ - INFO - ==================================================
2025-07-21 13:30:41,640 - __main__ - INFO - FINAL RESULTS
2025-07-21 13:30:41,640 - __main__ - INFO - ==================================================
2025-07-21 13:30:41,640 - __main__ - INFO - Training results: TrainOutput(global_step=35940, training_loss=0.23766242132362023, metrics={'train_runtime': 5916.7399, 'train_samples_per_second': 388.748, 'train_steps_per_second': 6.074, 'total_flos': 7.617266201546035e+16, 'train_loss': 0.23766242132362023, 'epoch': 3.0})
2025-07-21 13:30:41,640 - __main__ - INFO - Evaluation results: {'eval_loss': 0.2821662724018097, 'eval_runtime': 54.2454, 'eval_samples_per_second': 1570.455, 'eval_steps_per_second': 24.555, 'epoch': 3.0}
2025-07-21 13:30:41,641 - __main__ - INFO - Saving final model and tokenizer...
2025-07-21 13:30:42,179 - __main__ - INFO - Model and tokenizer saved to: ./Distilbert-finetuned/final-model
2025-07-21 13:30:42,179 - __main__ - INFO - ==================================================
2025-07-21 13:30:42,179 - __main__ - INFO - TRAINING SESSION COMPLETED SUCCESSFULLY
2025-07-21 13:30:42,179 - __main__ - INFO - ==================================================
